{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_TP2_TAZROUTE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmYvDDt3OClU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57caf462-d22b-4a88-b8c4-7af0c7da3569"
      },
      "source": [
        "#Mount your google drive: require authorization\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfAY7OEuOtmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7351a59b-2991-4155-89be-d6f08e6b9e16"
      },
      "source": [
        "#Launch some linux commands by adding \"!\" before a command\n",
        "!pwd\n",
        "!ls\n",
        "!ls drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "drive  sample_data\n",
            "'Colab Notebooks'\t\t        Model\n",
            " Documents_Saad\t\t\t       'Paris test'\n",
            "'Documents stagiaire'\t\t       'rapport lailouette'\n",
            "'Documents Visa 2021 2022'\t       'Rapport LVMT'\n",
            " Donda\t\t\t\t        Recovery\n",
            " ECM\t\t\t\t        ressourcessss\n",
            " gifs\t\t\t\t       'RIB SAAD TAZROUTE.pdf'\n",
            " Imagetest\t\t\t        SmallDrone\n",
            " Inside-Two-i-S02E15-Anomalies-V2.mp4  'Visa Saad.rar'\n",
            " main_CV2_21.gdoc\t\t        Work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snv-W5TgOvUT"
      },
      "source": [
        "#Change your location in the arborescence\n",
        "import os\n",
        "#################################################CHANGE TO YOUR PATH\n",
        "os.chdir('/content/drive/MyDrive/ECM/ComputerVision/')#########################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMboH93MPErm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4936db08-89a0-4394-dec3-e91fa4bbcecb"
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ECM/ComputerVision\n",
            " CV_TP1_21_students.ipynb   img2.ppm   img5.ppm       main_CV1_21.pdf\n",
            " CV_TP2_21_students.ipynb   img3.ppm  'Large scale'   main_CV2_21.pdf\n",
            " img1.ppm\t\t    img4.ppm   lena.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3HTzwn0OOUS"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6JB8U-JT3Pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b513c3-b197-4a9f-9196-52f58371589a"
      },
      "source": [
        "#Load MNIST Dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "#from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "\n",
        "print(mnist.data.shape)\n",
        "print(mnist.target.shape)\n",
        "print(np.unique(mnist.target))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n",
            "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycJybiLNKnw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp64FTdbUTFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a36a34-b77c-4f2e-d83e-37655d5ad532"
      },
      "source": [
        "\n",
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')\n",
        "print(type(mnist))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LL_75pv-BpI"
      },
      "source": [
        "##Build your dataset\n",
        "\n",
        "Take the first 300 digits as your dataset.\n",
        "\n",
        "Reshape the image data into 28*28 images and display one of them using cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "961WNRqE-ZM4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "58bd7e57-f7eb-4fed-d634-ca9eb96104eb"
      },
      "source": [
        "X = mnist.data[:300]\n",
        "y = mnist.target[:300]\n",
        "print(X.shape)\n",
        "X = np.reshape(X, (300,28, 28))\n",
        "print(X.shape)\n",
        "#displayed the second image of the X set\n",
        "cv2_imshow(X[2])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 784)\n",
            "(300, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMTAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjwFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEVj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3965665210>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fab61ol_-aUu"
      },
      "source": [
        "## Extract dense features\n",
        "\n",
        "For each image extract dense daisy features using the following code.\n",
        "\n",
        "More information on daisy can be found here: https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_daisy.html\n",
        "\n",
        "Make sure you reshape the output to obtain a 2d array per image (nb features * feature dimension)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny6xOIJr0D6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356265ff-d78e-491f-a435-9fdd92b7d079"
      },
      "source": [
        "from skimage.feature import daisy\n",
        "from skimage import data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "full_descs = []\n",
        "\n",
        "for t in range(len(X)):\n",
        "  img  = X[t]\n",
        "  descs, descs_img = daisy(img, step=2, radius=8, rings=2, histograms=6, orientations=8, visualize=True)  #sortie (6x6x104) ====} (36,104) pour chaque feature \n",
        "  descs = np.reshape(descs,(36,104))\n",
        "\n",
        "  full_descs.append(descs)\n",
        "full_descs = np.array(full_descs)\n",
        "print(full_descs.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "(300, 36, 104)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-agnirH-_QGW"
      },
      "source": [
        "## Normalization\n",
        "\n",
        "Perform l2 normalization on each feature descriptor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcggULUaAC1s"
      },
      "source": [
        "import sklearn\n",
        "full_desc = []\n",
        "for feature in full_descs :\n",
        "  feature = sklearn.preprocessing.normalize(feature, norm=\"l2\")\n",
        "  full_desc.append(feature)\n",
        "full_desc = np.array(full_desc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBMqiN9rDgWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4c3861-3d8e-4bc8-e27c-433653112924"
      },
      "source": [
        "#You can check that the normalization is properly done.\n",
        "print(np.sum(np.power(full_desc[0,0,:],2.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb-00B_xAZYq"
      },
      "source": [
        "##Clustering and embeddings\n",
        "\n",
        "Look and try to understand the following codes.\n",
        "These aggregators include the clustering.\n",
        "\n",
        "After dividing your data into train and test set, perform the clustering with k=100 clusters on all the features of the train set.\n",
        "\n",
        "Then, compute the bow and vlad descriptors for each image of the train and test sets.\n",
        "\n",
        "Pay attention to the normalization apllied on the computed embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cD8eQofWeYq",
        "outputId": "9654cd19-b891-4a40-c0bd-4540f49c7eee"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(full_desc, y, test_size=0.33, random_state=42, shuffle = True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
        "print(X_test.shape)\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=100, random_state=0).fit(X_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(201, 36, 104)\n",
            "(201,)\n",
            "(99, 36, 104)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUSMSdHuBxtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fd702b-7852-42cd-ace4-af627050e366"
      },
      "source": [
        "!pip install feature-aggregation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting feature-aggregation\n",
            "  Downloading feature_aggregation-0.3-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from feature-aggregation) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->feature-aggregation) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->feature-aggregation) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->feature-aggregation) (1.0.1)\n",
            "Installing collected packages: feature-aggregation\n",
            "Successfully installed feature-aggregation-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zyt3p7OFqTP"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "\n",
        "class BaseAggregator(BaseEstimator):\n",
        "    \"\"\"Implement any functions that can be shared among all feature\n",
        "    aggregation methods.\"\"\"\n",
        "\n",
        "    def __init__(self, dimension_ordering=\"tf\"):\n",
        "        self.dimension_ordering = dimension_ordering\n",
        "\n",
        "    def _reshape_local_features(self, X):\n",
        "        \"\"\"Reshape a n-dimensional array into a 2d array of local features.\n",
        "        Account for the case that X is a list because not all samples have\n",
        "        the same number of local features.\n",
        "        \"\"\"\n",
        "        if len(X) == 0:\n",
        "            raise ValueError(\"X cannot be empty\")\n",
        "\n",
        "        dims = len(X[0]) if self.dimension_ordering == \"th\" else X[0].shape[-1]\n",
        "        if isinstance(X, list):\n",
        "            arrays = [\n",
        "                x.T.reshape(-1, dims)\n",
        "                if self.dimension_ordering == \"th\"\n",
        "                else x.reshape(-1, dims)\n",
        "                for x in X\n",
        "            ]\n",
        "            lengths = [len(x) for x in arrays]\n",
        "            X = np.vstack(arrays)\n",
        "        else:\n",
        "            if self.dimension_ordering == \"th\":\n",
        "                X = X.transpose(*([0] + range(2, len(X.shape)) + [1]))\n",
        "            lengths = [int(np.prod(X.shape[1:-1]))]*X.shape[0]\n",
        "            X = X.reshape(-1, dims)\n",
        "\n",
        "        return X, lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3UBhgPTFhCA"
      },
      "source": [
        "\"\"\"Quantize local features and aggregate them in a Bag Of Words manner\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import cluster\n",
        "\n",
        "#from .base import BaseAggregator\n",
        "\n",
        "\n",
        "class BagOfWords(BaseAggregator):\n",
        "    \"\"\"Compute a Bag of Words model and aggregate local features with it.\n",
        "    \n",
        "    Train a MiniBatchKMeans on the data and then use the centroids as a\n",
        "    codebook to encode any set of local features.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_codewords : int\n",
        "                  The codebook size aka the number of clusters\n",
        "    l1_norm : boolean\n",
        "              Whether to normalize the transformed data or not\n",
        "    dimension_ordering : {'th', 'tf'}\n",
        "                         Changes how n-dimensional arrays are reshaped to form\n",
        "                         simple local feature matrices. 'th' ordering means the\n",
        "                         local feature dimension is the second dimension and\n",
        "                         'tf' means it is the last dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_codewords, l1_norm=True, dimension_ordering=\"tf\"):\n",
        "        self.n_codewords = n_codewords\n",
        "        self.l1_norm = l1_norm\n",
        "        self._clusterer = cluster.MiniBatchKMeans(\n",
        "            n_clusters=self.n_codewords,\n",
        "            n_init=1,\n",
        "            compute_labels=False\n",
        "        )\n",
        "\n",
        "        super(self.__class__, self).__init__(dimension_ordering)\n",
        "\n",
        "    @property\n",
        "    def centroids(self):\n",
        "        \"\"\"The centroids of the encoding\"\"\"\n",
        "        return self._clusterer.cluster_centers_.copy()\n",
        "\n",
        "    @centroids.setter\n",
        "    def centroids(self, _centroids):\n",
        "        self._clusterer.cluster_centers_ = _centroids.copy()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Build the codebook for the Bag of Words model.\n",
        "        Apply the clustering algorithm to the data and use the cluster centers\n",
        "        as codewords for the codebook.\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array_like or list\n",
        "            The local features to train on. They must be either nd arrays or\n",
        "            a list of nd arrays.\n",
        "        \"\"\"\n",
        "        X, _ = self._reshape_local_features(X)\n",
        "\n",
        "        self._clusterer.fit(X)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def partial_fit(self, X, y=None):\n",
        "        \"\"\"Partially learn the codebook from the provided data.\n",
        "        Run a single iteration of the minibatch KMeans on the provided data.\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array_like or list\n",
        "            The local features to train on. They must be either nd arrays or\n",
        "            a list of nd arrays.\n",
        "        \"\"\"\n",
        "        X, _ = self._reshape_local_features(X)\n",
        "        self._clusterer.partial_fit(X)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Compute the Bag of Words representation of the provided data.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array_like or list\n",
        "            The local features to aggregate. They must be either nd arrays or\n",
        "            a list of nd arrays. In case of a list each item is aggregated\n",
        "            separately.\n",
        "        \"\"\"\n",
        "        # Get the local features and the number of local features per document\n",
        "        X, lengths = self._reshape_local_features(X)\n",
        "\n",
        "        # Preprocess the lengths list into indexes in the local feature array\n",
        "        starts = np.cumsum([0] + lengths).astype(int)\n",
        "        ends = np.cumsum(lengths).astype(int)\n",
        "\n",
        "        # Transform and aggregate the local features\n",
        "        words = self._clusterer.predict(X)\n",
        "        bow = np.vstack([\n",
        "            np.histogram(\n",
        "                words[s:e],\n",
        "                bins=np.arange(self.n_codewords + 1) - 0.5,\n",
        "                density=False\n",
        "            )[0]\n",
        "            for s, e in zip(starts, ends)\n",
        "        ])\n",
        "\n",
        "        if self.l1_norm:\n",
        "            bow = bow.astype(float) / bow.sum(axis=1).reshape(-1, 1)\n",
        "\n",
        "        return bow\n",
        "\n",
        "    def inertia(self, X):\n",
        "        \"\"\"Return the value of the KMeans objective function on the provided\n",
        "        data.\n",
        "        X : array_like or list\n",
        "            The local features to train on. They must be either nd arrays or\n",
        "            a list of nd arrays.\n",
        "        \"\"\"\n",
        "        X, _ = self._reshape_local_features(X)\n",
        "\n",
        "        return -self._clusterer.score(X)\n",
        "\n",
        "    def score(self, X, y=None):\n",
        "        \"\"\"Return the negative inertia so that the best score is the max\n",
        "        score.\n",
        "        X : array_like or list\n",
        "            The local features to train on. They must be either nd arrays or\n",
        "            a list of nd arrays.\n",
        "        \"\"\"\n",
        "        return -self.inertia(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18okIVFOHU8k"
      },
      "source": [
        "\"\"\"Quantize local features and aggregate them using the Vector of Locally\n",
        "Aggregated Descriptors (VLAD) encoding\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import cluster\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "\n",
        "class Vlad(BaseAggregator):\n",
        "    \"\"\"Compute a VLAD model and aggregate local features with it.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_codewords: int\n",
        "                 The codebook size aka the number of clusters.\n",
        "    inner_batch: int\n",
        "                 The batch size used to compute the differences between\n",
        "                 the feature descriptors and the centroids.\n",
        "    normalization: int\n",
        "                   A bitmask of possible normalizations\n",
        "    dimension_ordering : {'th', 'tf'}\n",
        "                         Changes how n-dimensional arrays are reshaped to form\n",
        "                         simple local feature matrices. 'th' ordering means the\n",
        "                         local feature dimension is the second dimension and\n",
        "                         'tf' means it is the last dimension.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    POWER_NORMALIZATION = 1\n",
        "    L2_NORMALIZATION = 2\n",
        "\n",
        "    def __init__(self, n_codewords, normalization=3, inner_batch=128,\n",
        "                 dimension_ordering=\"tf\"):\n",
        "        self.n_codewords = n_codewords\n",
        "        self.inner_batch = inner_batch\n",
        "        self.normalization = normalization\n",
        "\n",
        "        self._clusterer = cluster.MiniBatchKMeans(\n",
        "            n_clusters=self.n_codewords,\n",
        "            n_init=1,\n",
        "            compute_labels=False\n",
        "        )\n",
        "\n",
        "        super(self.__class__, self).__init__(dimension_ordering)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Build the codebook for the VLAD model using KMeans.\n",
        "        Apply the clustering algorithm to the data and use the cluster centers\n",
        "        as codewords for the codebook.\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array_like or list\n",
        "            The local features to train on. They must be either nd arrays or\n",
        "            a list of nd arrays.\n",
        "        \"\"\"\n",
        "        X, _ = self._reshape_local_features(X)\n",
        "\n",
        "        self._clusterer.fit(X)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def partial_fit(self, X, y=None):\n",
        "        \"\"\"Partially learn the codebook from the provided data.\n",
        "        Run a single iteration of the minibatch KMeans on the provided data.\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array_like or list\n",
        "            The local features to train on. They must be either nd arrays or\n",
        "            a list of nd arrays.\n",
        "        \"\"\"\n",
        "        X, _ = self._reshape_local_features(X)\n",
        "        self._clusterer.partial_fit(X)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Compute the Bag of Words representation of the provided data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array_like or list\n",
        "            The local features to aggregate. They must be either nd arrays or\n",
        "            a list of nd arrays. In case of a list each item is aggregated\n",
        "            separately.\n",
        "        \"\"\"\n",
        "        # Get the local features and the number of local features per document\n",
        "        X, lengths = self._reshape_local_features(X)\n",
        "\n",
        "        # Preprocess the lengths list into indexes in the local feature array\n",
        "        starts = np.cumsum([0] + lengths).astype(int)\n",
        "        ends = np.cumsum(lengths).astype(int)\n",
        "\n",
        "        words = self._clusterer.predict(X)\n",
        "        dims = len(X[0])\n",
        "\n",
        "        vlad = np.zeros((len(lengths), dims*self.n_codewords))\n",
        "        v = np.zeros((self.inner_batch, self.n_codewords, dims))\n",
        "        for i, (s, e) in enumerate(zip(starts, ends)):\n",
        "            for j in range(s, e, self.inner_batch):\n",
        "                ee = min(j+self.inner_batch, e)\n",
        "\n",
        "                v.fill(0)\n",
        "                v[range(ee-j), words[j:ee]] = \\\n",
        "                    X[j:ee] - self._clusterer.cluster_centers_[words[j:ee]]\n",
        "                vlad[i] += v[:ee-j].sum(axis=0).ravel()\n",
        "            vlad[i] /= lengths[i]\n",
        "        \n",
        "        # Check if we should be normalizing the power\n",
        "        if self.normalization & self.POWER_NORMALIZATION:\n",
        "            vlad = np.sqrt(np.abs(vlad))*np.sign(vlad)\n",
        "\n",
        "        # Check if we should be performing L2 normalization\n",
        "        if self.normalization & self.L2_NORMALIZATION:\n",
        "            vlad /= np.sqrt(np.sum(vlad**2, axis=1)).reshape(-1, 1)\n",
        "\n",
        "        return vlad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr29NGsuOMnW",
        "outputId": "edd01f19-5d7c-4541-927f-bd1a2f49d6e7"
      },
      "source": [
        "X?shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVunRpIABndr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ece78c1-5dd9-4176-8688-93d27e2be9c8"
      },
      "source": [
        "vlad  = Vlad(n_codewords=100)\n",
        "vlad.fit(X_train)\n",
        "\n",
        "X_preds_vlad = vlad.transform(X_test)\n",
        "print(X_preds_vlad[0].shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "374400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VclORATiBnp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa1b7e2-9828-459e-dbe0-0b5103b9a625"
      },
      "source": [
        "bow = BagOfWords(n_codewords=100)\n",
        "bow.fit(X_train)\n",
        "\n",
        "X_preds_bow = bow.transform(X_test)\n",
        "\n",
        "print(X_preds_bow[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsxa0pDzFQZN"
      },
      "source": [
        "##Some questions: \n",
        "\n",
        "- what is the dimension of BOW, VLAD and Fisher vectors ? \n",
        "    - **voir code cell ci-dessous**\n",
        "- what is the power normalization ? \n",
        "\n",
        "- what are the parameters of the clustering computed by kmeans ? \n",
        "    -  **Nombres de cluster + Terme de régularisation  + Init : qui permet de définir comment o initialise nos centroids + degree : degrès du polynome de kernelisation**\n",
        "\n",
        "- what are those of the GMM ?\n",
        "    - **Nombres de mixtures + Type de covariance + seuil de convergence (L'algo de maximisation d'esperance s'arrete lorsqu'il arrive à cet erreur )**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgjmJLyK6KPl",
        "outputId": "af5c87d6-4d09-4566-fc54-1c39b2f59f5a"
      },
      "source": [
        "\n",
        "#Dimension of VLAD  vectors\n",
        "print(\"dimension du vecteur de features VALD\",X_preds_vlad[0].shape)    # k = 2925\n",
        "X_preds_bow = bow.transform(X_test)\n",
        "\n",
        "#Dimension of bow  vectors\n",
        "print(\"dimension du vecteur de features BOW\",X_preds_bow[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension du vecteur de features VALD (374400,)\n",
            "dimension du vecteur de features BOW (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6oOnPhtBmba"
      },
      "source": [
        "## Classification with SVM\n",
        "\n",
        "For BOW and VLAD perform classification of the small MNIST dataset with linear SVMs.\n",
        "\n",
        "Make sure your descriptors are L2-normalized and use sklearn:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "- give results for all encoding and various C values.\n",
        "- compare BOW and VLAD to using the full image (flatten) as input.\n",
        "- compute the kernels on train and test sets and compute the SVM again\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp0_YlxmDQfb"
      },
      "source": [
        "\n",
        "import sklearn\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import norma\n",
        "\n",
        "\n",
        "# pipeline comme décrite dans le cours + variation du param C sur [0,0.1,0.2, ... , 1]\n",
        "# storing results Ypred et scores sur \n",
        "param = np.linspace(0, 1, 11)\n",
        "YPRED = []\n",
        "SCORES = []\n",
        "for c in param : \n",
        "  clf = make_pipeline(Vlad(n_codewords=100),StandardScaler(), sklearn.svm.SVC(C=c))\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  YPRED.append(y_pred)\n",
        "  scores = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
        "  SCORES.append(scores)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7oxuAS-kMIwy",
        "outputId": "e1e420ac-fa78-4cdf-c02c-b1613b527672"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# plot matrce de confusion\n",
        "sns.heatmap(confusion_matrix(y_test, YPRED[0]),annot=True,lw =2,cbar=False)\n",
        "plt.ylabel(\"True Values\")\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.title(\"CONFUSION MATRIX VISUALIZATION\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okhn2Mr1CmES"
      },
      "source": [
        ""
      ]
    }
  ]
}