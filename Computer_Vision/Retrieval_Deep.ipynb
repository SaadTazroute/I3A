{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_TP4_TAZROUTE_retrieval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7UnqoBcPVNB"
      },
      "source": [
        "# Recognition - Image retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SO5UoiqPVNG"
      },
      "source": [
        "Image retrieval, Content-Based Image Retrieval (CBIR) is a problem of the computer vision field.\n",
        "The goal is to retrieve images similar to a given query image in an unlabeled (possibly large) database of images.\n",
        "\n",
        "We will build a pipeline to perform such process.\n",
        "The program will sort out the images in terms of similarity to the query.\n",
        "We'll use several pethods and compare their performances.\n",
        "\n",
        "Oxford 5k retrieval dataset: http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/\n",
        "\n",
        "credit to Filip Radenovic\n",
        "https://github.com/filipradenovic/revisitop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reGhkJ1APVNI"
      },
      "source": [
        "Overview:\n",
        "\n",
        "Using Filips code: compute performance on roxford5k based on pretrained features (python3).\n",
        "\n",
        "Code mAP computation\n",
        "\n",
        "Play with Keras\n",
        "Use a pre-trained network\n",
        "Compute global descriptors\n",
        "Apply L2 normalization\n",
        "Compute similarity and measure performance\n",
        "\n",
        "More fun: \n",
        "Apply PCA to reduce the size of descriptors\n",
        "Extract different layers\n",
        "Extract description from different networks: inception, ResNet, DenseNet, etc.\n",
        "Build a new dataset: faces, human letters, any crazy idea.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFk_NLqHR324"
      },
      "source": [
        " ### Using Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0_Rvh2mRsIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1709602d-60fe-4cc9-fbde-e28c681a5d7e"
      },
      "source": [
        "#mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\") # Don't change this.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW6rzGanR1S1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958cb0de-9e44-47b6-bf74-397f06ee6c76"
      },
      "source": [
        "#!ls drive/My\\ Drive\n",
        "import os\n",
        "#################################################CHANGE TO YOUR PATH\n",
        "os.chdir('/content/drive/MyDrive/ECM/ComputerVision/TP4_ret_archive_Etus21/python/')###################################################\n",
        "\n",
        "!pwd\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ECM/ComputerVision/TP4_ret_archive_Etus21/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYCMAN-YSUdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1167ba87-8300-4688-d010-000341b4e7a0"
      },
      "source": [
        "!pwd\n",
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ECM/ComputerVision/TP4_ret_archive_Etus21/python\n",
            "CV_TP4_retrieval21_TAZROUTE.ipynb  example_process_distractors.py\n",
            "dataset.py\t\t\t   example_process_images.py\n",
            "dataset.pyc\t\t\t   feat_vgg19_C5_avg_l2.npy\n",
            "download.py\t\t\t   imlist.npy\n",
            "download.pyc\t\t\t   __pycache__\n",
            "evaluate.py\t\t\t   Qfeat_vgg19_C5_avg_l2.npy\n",
            "evaluate.pyc\t\t\t   qimlist.npy\n",
            "example_evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RJKPf32PVNU"
      },
      "source": [
        "# Use Filip's code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BowRRhXKPVNX"
      },
      "source": [
        "### Download the image dataset and precomputed features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmVNuOwSSYgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edfe1ebb-9ef0-4190-89b3-7edf8dfa5bd7"
      },
      "source": [
        "!mkdir /content/data\n",
        "!ls /content/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Su1Hr-YPVNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816ab4f6-012d-4c55-a5a6-ed595623b207"
      },
      "source": [
        "from download import *\n",
        "\n",
        "\n",
        "download_datasets(\"/content/data\")###########################################\n",
        "download_features(\"/content/data\")###########################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Dataset roxford5k directory does not exist. Creating: /content/data/datasets/roxford5k/jpg\n",
            ">> Downloading dataset roxford5k archive oxbuild_images.tgz...\n",
            ">> Extracting dataset roxford5k archive oxbuild_images.tgz...\n",
            ">> Extracted, deleting dataset roxford5k archive oxbuild_images.tgz...\n",
            ">> Downloading dataset roxford5k ground truth file...\n",
            ">> Downloading dataset roxford5k features file roxford5k_resnet_rsfm120k_gem.mat...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2WU5wkGYtOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7009b062-f48a-451e-9d85-608f56368593"
      },
      "source": [
        "!ls /content/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets  features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V48CKqVPVNf"
      },
      "source": [
        "### Evaluate the downloaded features performances on roxford5k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J29oFwm4PVNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47523e46-fd2f-40dc-c0ef-b2b8997002f4"
      },
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from scipy.io import loadmat\n",
        "\n",
        "from dataset import configdataset\n",
        "from download import download_datasets, download_features\n",
        "from evaluate import compute_map\n",
        "\n",
        "data_root = \"/content/data\"###########################################\n",
        "\n",
        "# Set test dataset: roxford5k | rparis6k\n",
        "test_dataset = 'roxford5k'\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "# Evaluate\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "print('>> {}: Evaluating test dataset...'.format(test_dataset)) \n",
        "# config file for the dataset\n",
        "# separates query image list from database image list, when revisited protocol used\n",
        "cfg = configdataset(test_dataset, os.path.join(data_root, 'datasets'))\n",
        "(cfg)\n",
        "# load query and database features\n",
        "print('>> {}: Loading features...'.format(test_dataset))    \n",
        "features = loadmat(os.path.join(data_root, 'features', '{}_resnet_rsfm120k_gem.mat'.format(test_dataset)))\n",
        "Q = features['Q']\n",
        "X = features['X']\n",
        "\n",
        "# perform search\n",
        "print('>> {}: Retrieval...'.format(test_dataset))\n",
        "sim = np.dot(X.T, Q)\n",
        "ranks = np.argsort(-sim, axis=0)\n",
        "\n",
        "# revisited evaluation\n",
        "gnd = cfg['gnd']\n",
        "\n",
        "# search for easy\n",
        "gnd_t = []\n",
        "for i in range(len(gnd)):\n",
        "    g = {}\n",
        "    g['ok'] = np.concatenate([gnd[i]['easy']])\n",
        "    g['junk'] = np.concatenate([gnd[i]['junk'], gnd[i]['hard']])\n",
        "    gnd_t.append(g)\n",
        "#mapE, apsE, mprE, prsE = compute_map(ranks, gnd_t, ks)\n",
        "mapE, apsE, mprE, prsE = compute_map(ranks, gnd_t)\n",
        "\n",
        "# search for easy & hard\n",
        "gnd_t = []\n",
        "for i in range(len(gnd)):\n",
        "    g = {}\n",
        "    g['ok'] = np.concatenate([gnd[i]['easy'], gnd[i]['hard']])\n",
        "    g['junk'] = np.concatenate([gnd[i]['junk']])\n",
        "    gnd_t.append(g)\n",
        "#mapM, apsM, mprM, prsM = compute_map(ranks, gnd_t, ks)\n",
        "mapM, apsM, mprM, prsM = compute_map(ranks, gnd_t)\n",
        "\n",
        "# search for hard\n",
        "gnd_t = []\n",
        "for i in range(len(gnd)):\n",
        "    g = {}\n",
        "    g['ok'] = np.concatenate([gnd[i]['hard']])\n",
        "    g['junk'] = np.concatenate([gnd[i]['junk'], gnd[i]['easy']])\n",
        "    gnd_t.append(g)\n",
        "#mapH, apsH, mprH, prsH = compute_map(ranks, gnd_t, ks)\n",
        "mapH, apsH, mprH, prsH  = compute_map(ranks, gnd_t)\n",
        "\n",
        "print('>> {}: mAP E: {}, M: {}, H: {}'.format(test_dataset, np.around(mapE*100, decimals=2), np.around(mapM*100, decimals=2), np.around(mapH*100, decimals=2)))\n",
        "#print('>> {}: mP@k{} E: {}, M: {}, H: {}'.format(test_dataset, np.array(ks), np.around(mprE*100, decimals=2), np.around(mprM*100, decimals=2), np.around(mprH*100, decimals=2)))\n",
        "\n",
        "\n",
        "#####map2, aps2 = My_compute_map(sim, gnd_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> roxford5k: Evaluating test dataset...\n",
            ">> roxford5k: Loading features...\n",
            ">> roxford5k: Retrieval...\n",
            ">> roxford5k: mAP E: 84.81, M: 64.67, H: 38.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr7AEzQ7_kZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e4781c-70f0-4eec-d4e4-14150f67e6d7"
      },
      "source": [
        "print(ranks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2956 4290  581 3041 2293 3112 2651 3431 1258 2651 3829  933  607 3829\n",
            "  607 4538  314  314 1506 1884  631  631 2868 3080 3218 2468 2468 2468\n",
            " 2468 2468 4883 1242 4883 1654  972 3951 3951 3951 3951 3951 3798 1986\n",
            " 1986   86 3798 3723 3723 3723 3723 3723 4300 1946 2319 2752 4706   69\n",
            "  239 3907 4725 3112 3431 4586 4803  655 1767 1767  759 4659  248 2641]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouD0ZW7zPVNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f878e3-d04a-4363-c118-75078372b730"
      },
      "source": [
        "print(Q.shape)\n",
        "print(X.shape)\n",
        "\n",
        "print(sim.shape)\n",
        "print(ranks.shape)\n",
        "print(len(gnd_t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2048, 70)\n",
            "(2048, 4993)\n",
            "(4993, 70)\n",
            "(4993, 70)\n",
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrzIo4FyPVNv"
      },
      "source": [
        "### Here is a fonction that performs L2 normalisation\n",
        "Code your own one and check whether you obtain the same results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTRi5-1fPVNx"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# return descriptors that are L2 normalized\n",
        "def My_norm_L2(x,axis):\n",
        "    \n",
        "    return(normalize(x, norm='l2', axis=axis))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKIq7CzYPVNs"
      },
      "source": [
        "# Do some coding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVsPiHQhEhPq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grJi115fEhi5"
      },
      "source": [
        "Q = features['Q']\n",
        "X = features['X']\n",
        "X = My_norm_L2(X,0)\n",
        "Q = My_norm_L2(Q,0)\n",
        "sim = np.dot(X.T, Q)\n",
        "ranks = np.argsort(-sim, axis=0)\n",
        "# search for easy\n",
        "gnd_t = []\n",
        "for i in range(len(gnd)):\n",
        "    g = {}\n",
        "    g['ok'] = np.concatenate([gnd[i]['easy']])\n",
        "    g['junk'] = np.concatenate([gnd[i]['junk'], gnd[i]['hard']])\n",
        "    gnd_t.append(g)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOqeNsxyFMBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82428fe3-65fc-439b-eddb-3b6891b12945"
      },
      "source": [
        "ranks.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4993, 70)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE-MbvbqPVN3"
      },
      "source": [
        "### TO DO: code a fonction that compute the mAP (mean average precision)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvGZMgvaPVN5"
      },
      "source": [
        "# compute mean Average Precision given the ground truth\n",
        "def My_compute_map(sim, gt):\n",
        "    \n",
        "    return map, aps\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL4rA7TbQUjr"
      },
      "source": [
        "def computeee_ap(sim, nres):\n",
        "    ranks = np.argsort(-sim, axis=0)\n",
        "    nimgranks = len(ranks)\n",
        "\n",
        "    # accumulate trapezoids in PR-plot\n",
        "    ap = 0\n",
        "\n",
        "    recall_step = 1. / nres\n",
        "\n",
        "    for j in np.arange(nimgranks):\n",
        "        rank = ranks[j]\n",
        "\n",
        "        if rank == 0:\n",
        "            precision_0 = 1.\n",
        "        else:\n",
        "            precision_0 = float(j) / rank\n",
        "\n",
        "        precision_1 = float(j + 1) / (rank + 1)\n",
        "\n",
        "        ap += (precision_0 + precision_1) * recall_step / 2.\n",
        "\n",
        "    return ap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbZXuAjFPXLB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aYO6ujNTsP1"
      },
      "source": [
        "def My_compute_map(ranks, gt):\n",
        "\n",
        "\n",
        "    map = 0.\n",
        "    nq = len(gt) \n",
        "    aps = np.zeros(nq) # list of average precision for each queries\n",
        "\n",
        "    for i in range(len(gt)):\n",
        "        gt_ok = np.array(gt[i]['ok'])\n",
        "\n",
        "\n",
        "\n",
        "        gt_junk = np.array(gnd[i]['junk'])\n",
        "\n",
        "# positions ordonées d'images positives + junk voir pos/junk\n",
        "        gt_ok = np.array(gt[i]['ok'])\n",
        "  # les deux boucles permettent de generer des listes pour chaque queries [T,T,F,T ....]\n",
        "        pos= []\n",
        "        for x in np.arange(ranks.shape[0]) : \n",
        "            if ranks[x,i] in gt_ok:\n",
        "                pos.append(True)\n",
        "            else : \n",
        "                pos.append(False)\n",
        "        junk=[]\n",
        "        for x in np.arange(ranks.shape[0]) : \n",
        "            if ranks[x,i] in gt_junk:\n",
        "                junk.append(True)\n",
        "            else : \n",
        "                junk.append(False)\n",
        "\n",
        "\n",
        "        \n",
        "        if len(junk)== 0:  # tout élément dans le ranking sera positive (sum de 1 / nb d'échantillons = 1)\n",
        "            aps[i]=1\n",
        "            \n",
        "        else:\n",
        "            k = 0;\n",
        "            junk_index = 0;\n",
        "            # si une image FP apparait avant une image TP =====> il faut mettre à jour les indexs :\n",
        "            positive_index = 0\n",
        "            while (positive_index < len(pos)): # parcours de tout élément de la liste positive\n",
        "                while (junk_index < len(junk)):  # parcours de tout élément de la liste junk\n",
        "                  if pos[positive_index] > junk[junk_index]: \n",
        "                      k += 1   # compteur de parcours de la liste\n",
        "                      junk_index += 1   # l'é\n",
        "\n",
        "                pos[ip] = pos[ip] - k\n",
        "                ip += 1\n",
        "        # Calculer l'AP pour cette query\n",
        "        ap = computeee_ap(pos, gt_ok)\n",
        "        \n",
        "        aps[i] = ap\n",
        "\n",
        "        map = map + ap\n",
        "\n",
        "        pos += 1 # get it to 1-based\n",
        "    map = np.mean(aps)\n",
        "\n",
        "    return map,pos\n",
        "\n",
        "\n",
        "\n",
        "# link : https://stackoverflow.com/questions/40457331/information-retrieval-evaluation-python-precision-recall-f-score-ap-map\n",
        "\n",
        "#Explain the link between Average precision, precision and recall at each step."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFRC-q3-Qgax"
      },
      "source": [
        "mapH  = My_compute_map(ranks, gnd_t)\n",
        "mapH\n",
        "\n",
        "# la boucle de génération de gt pour chaque query ralentit le code / on peut penser à une fonction numpy qui peut faire ça (comme filipe a utilisé dans son repo )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rakynGdOPVOA"
      },
      "source": [
        "# Some deep learning now\n",
        "\n",
        "Have a look at https://keras.io/ and https://keras.io/applications/\n",
        "We will now work on applying a pre-trained Network to the roxford5k dataset.\n",
        "\n",
        "## To do:\n",
        "We want to build global descriptors for each image of the dataset (and for all the queries).\n",
        " - build a descriptor based on the last convolutionnal layer (perform average pooling)\n",
        " - similarly build a descriptor based on the two first fully-connected layers.\n",
        " - measure performance for each extraction method.\n",
        " \n",
        "Note 1: similarity measure between queries and images of the database is performed by l2 normalizing all vectors then dot product.\n",
        "\n",
        "Note 2: the performance will be measured for the hard version of the ground truth. You may not consider junk images in our case.\n",
        "\n",
        "Note 3: performance wil be low (~7 to 15% map). It's normal.\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtk4TdHjPVOC"
      },
      "source": [
        "datapath = '../data/datasets/roxford5k/jpg/'####################################################\n",
        "\n",
        "network = VGG19(weights='imagenet')#, input_shape=(fscale, fscale, 3))\n",
        "network = Model(inputs=network.input, outputs=network.get_layer('fc2').output)#Use only the pre-trained convolutional layers\n",
        "network.trainable = Falsedatapath = '../data/datasets/roxford5k/jpg/'####################################################\n",
        "\n",
        "\n",
        "qname = np.load('qimlist.npy')\n",
        "\n",
        "fname = np.load('imlist.npy')\n",
        "\n",
        "all_qfeat = np.zeros(shape=(len(qname),4096), dtype=np.float32)\n",
        "#im_batch_Q = np.zeros(shape=(len(qname),224,224,3), dtype=np.float32)\n",
        "\n",
        "all_feat = np.zeros(shape=(len(fname),4096), dtype=np.float32)\n",
        "#im_batch = np.zeros(shape=(len(fname),224,224,3), dtype=np.float32)\n",
        "\n",
        "cpt = 0\n",
        "for i in range(len(qname)):\n",
        "    img_path = os.path.join(datapath,qname[i]+'.jpg')\n",
        "\n",
        "    t = time.time()\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    #im_batch_Q[cpt,:,:,:] = x\n",
        "\n",
        "    qfeatures = network.predict(x)\n",
        "    #qfeatures = qfeatures.flatten()\n",
        "\n",
        "    all_qfeat[cpt,:]= qfeatures\n",
        "    cpt = cpt+1\n",
        "    elapsed = time.time() - t\n",
        "    print(elapsed)\n",
        "    print(cpt)\n",
        "\n",
        "cpt =0\n",
        "for i in range(len(fname)):\n",
        "    img_path = os.path.join(datapath,fname[i]+'.jpg')\n",
        "\n",
        "    t = time.time()\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    #im_batch[cpt,:,:,:] = x\n",
        "\n",
        "    features = network.predict(x)\n",
        "\n",
        "    all_feat[cpt,:]= features\n",
        "    cpt = cpt+1\n",
        "    elapsed = time.time() - t\n",
        "    print(elapsed)\n",
        "    print(cpt)\n",
        "\n",
        "np.save('all_feat_fc2.npy',all_feat)\n",
        "np.save('all_qfeat_fc2.npy',all_qfeat)\n",
        "#    all_feat = np.load('PATH_TO_MY_FILE.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xTDw4V0PVOK"
      },
      "source": [
        "# Tests can be performed here\n",
        "print(all_qfeat.shape)\n",
        "print(all_feat.shape)\n",
        "print(qfeatures.shape)\n",
        "all_qfeat_norm = My_norm_L2(all_qfeat,axis=1)\n",
        "all_feat_norm = My_norm_L2(all_feat,axis=1)\n",
        "print(np.sum(all_feat_norm**2.0, axis=1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lry02_mrBoHK"
      },
      "source": [
        "sim = np.dot(all_feat_norm, all_qfeat_norm.T)\n",
        "ranks = np.argsort(-sim, axis=0)\n",
        "ranks.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kscX_rVAC7SX"
      },
      "source": [
        "#getting ground truth / hard way\n",
        "\n",
        "\n",
        "gnd_t = []\n",
        "for i in range(len(gnd)):\n",
        "    g = {}\n",
        "    g['ok'] = np.concatenate([gnd[i]['easy']])\n",
        "    g['junk'] = np.concatenate([gnd[i]['junk'], gnd[i]['hard']])\n",
        "    gnd_t.append(g)\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrkQSh7wC_nW"
      },
      "source": [
        "mapH  = compute_map(ranks, gnd_t)\n",
        "mapH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S4tr40LGWTC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAMsZgqmPVOO"
      },
      "source": [
        "# j'ai pas su comment manipuler ceci / est ce ce sont des features extraites d'un vgg d'une couche autre que de laquelle j'ai coupé le réseau\n",
        "import numpy as np\n",
        "queries_c5 = np.load('Qfeat_vgg19_C5_avg_l2.npy')\n",
        "print(aa.shape)\n",
        "all_c5 = np.load('feat_vgg19_C5_avg_l2.npy')\n",
        "print(cc.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwRcqFhsaEvL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}