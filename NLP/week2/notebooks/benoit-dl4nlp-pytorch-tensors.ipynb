{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`pytorch` est une librairie de fonctions sur les tenseurs avec la plupart des fonctionnalités de numpy mais une api un peu différente. La documentation de référence est dispo en ligne : http://pytorch.org/docs/0.3.1/.\n",
    "\n",
    "Cette documentation n'est pas très avenante mais il est souvent utile de s'y référer lorsque l'on veut obtenir des résultats un peu exotiques. Ce notebook présente quelques fonctionnalités pratiques.\n",
    "\n",
    "Commençons par créer une matrice d'entiers aléatoires de taille (3, 6), et afficher sa transposée : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = (torch.rand(3, 6) * 20).long()\n",
    "print(x)\n",
    "print(x.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette matrice peut être redimensionnée en un tenseur du même nombre d'étélments mais avec d'autres dimensions en utlisant `view()`. Si on remplace une dimension par -1, celle ci est calculée automatiquement. La fonction `transpose()` permet de transposer deux dimensions en particulier; la fonction `size()`, ou `shape` dans les versions récentes de pytorch, donne les dimensions du tenseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(3, 2, 3)\n",
    "print(y)\n",
    "print(y.view(9, -1))\n",
    "print(y.transpose(0, 1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `size(d)` peut aussi donner la taille d'un axe en particulier, et la fonction `numel` renvoie le nombre d'éléments du tenseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.size(1))\n",
    "print(y.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de convertir un tenseur vers une représentation numpy et inversement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_y = y.numpy()\n",
    "torch.from_numpy(numpy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ajouter des dimensions de taille 1 avec `unsqueeze()` et les supprimer avec `squeeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = y.unsqueeze(2)\n",
    "print(y3.size())\n",
    "print(y3.squeeze().size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions `cat` et `split` permettent de concatèner tenseurs ou subdiviser un tenseur selon une dimension. La documentation donne les paramètres : http://pytorch.org/docs/0.3.1/torch.html#torch.split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = torch.rand(2, 3)\n",
    "b = torch.zeros(2, 3)\n",
    "print(a, b)\n",
    "c = torch.cat([a, b], 1)\n",
    "print(c)\n",
    "d, e = torch.split(c, 1, 0)\n",
    "print(d, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme `numpy`, pytorch permet de broadcaster des tenseurs de dimensions différentes (voir http://pytorch.org/docs/0.3.1/notes/broadcasting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting\n",
    "x = torch.rand(3, 1)\n",
    "y = torch.rand(3, 2)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire des multiplications de matrices avec la fonction `matmul`. Lorsque l'on a des tenseurs d'ordre 3 contenant des batches de matrices, on peut faire la multiplication de matrice batch par batch avec la fonction `bmm`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, 2)\n",
    "y = torch.rand(2, 3)\n",
    "print(x.matmul(y))\n",
    "\n",
    "x = torch.rand(2, 3, 2)\n",
    "y = torch.rand(2, 2, 3)\n",
    "print(x.bmm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utililisation du GPU est simple mais elle n'est pas automatique. On peut soit utiliser les types cuda (`torch.cuda.FloatTensor`), ou créer un tenseur sur CPU puis le migrer vers le gpu (`y = x.cuda()`). Le retour vers cpu se fait grâce à la fonction `x.cpu()`. Lorsqu'on applique une opération sur des tenseurs, ces derniers doivent être sur le même dispositif (cpu ou gpu) et le résultat est généré sur le même dispositif.\n",
    "\n",
    "Le passage CPU / GPU est coûteux, donc il faut éviter de le faire trop souvent. On peut par exemple copier toutes les données sur GPU en début d'apprentissage, ou alors le faire à chaque batch dans la boucle d'apprentissage.\n",
    "\n",
    "En plus d'envoyer les données, il faut appeler `model.cuda()` pour placer également les paramètres du modèle sur GPU.\n",
    "\n",
    "Un pattern souvent utilisé pour éviter de se poser trop de question est la création d'une fonction `Variable` qui s'occupe de placer les tenseurs sur GPU si une variable globale `cuda` le précise.\n",
    "\n",
    "Pour les systèmes multi-GPU, il est possible de choisir le GPU dans une clause `with`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.autograd\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "def Variable(tensor, volatile=False):\n",
    "    return torch.autograd.Variable(tensor.cuda() if cuda else tensor, volatile=volatile)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(10, 2)\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "model = Model()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "result = model(Variable(torch.rand(3, 10)))\n",
    "print(result.data)\n",
    "if cuda:\n",
    "    print(result.get_device())\n",
    "\n",
    "numpy_result = result.data.cpu().numpy()\n",
    "\n",
    "print(numpy_result)\n",
    "\n",
    "if cuda:\n",
    "    with torch.cuda.device(1):\n",
    "        x = torch.rand(3, 3).cuda()\n",
    "        print(x.get_device())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch permet de sauvegarder les modèles de deux manières. La première ne sauvegarde que les paramètres du modèle et est donc plus portable (néanmoins ces derniers ne peuvent être chargés que par pytorch). La seconde sauvegarde l'objet python contenant le modèle (un peu comme `pickle`) et le recharge directement. C'est plus pratique mais ne fonctionne que si on est dans le même répertoire avec le même code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pt\")\n",
    "\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"model_weights.pt\"))\n",
    "\n",
    "torch.save(model, \"full_model.pt\")\n",
    "model = torch.load(\"full_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi convertir les paramètres du modèle en objet numpy pour utilisation par exemple dans un autre langage. Il faut toutefois réimplémenter les mêmes opérations que dans `pytorch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_params = {name: value.cpu().numpy() for name, value in model.state_dict().items()}\n",
    "for name, param in numpy_params.items():\n",
    "    print(name, param.shape)\n",
    "    print(param)\n",
    "\n",
    "print('total number of parameters:', sum([p.numel() for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 1\n",
    "------------\n",
    "\n",
    "Avec l'aide de la documentation pytorch, calculez l'expression suivante :\n",
    "\n",
    "$\n",
    "a = 1_{(3\\times2)} \\\\\n",
    "b = sin(1 + \\sqrt{3 I_2} + 5 || a ||)\n",
    "$\n",
    "\n",
    "où $a$ est une matrice de taille (3, 2) contenant des 1, $I_2$ est la matrice identité de taille (2, 2) et $||\\cdot||$ est la norme 2 (norme euclidienne).\n",
    "\n",
    "Exercice 2\n",
    "----------\n",
    "\n",
    "Combien de paramètres a le modèle MLP du notebook précédent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
