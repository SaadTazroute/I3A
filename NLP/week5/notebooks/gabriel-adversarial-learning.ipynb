{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qg029q2A9eWg",
    "outputId": "d70f4c74-6111-4438-e991-d57ae6ea42af"
   },
   "outputs": [],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1j-PPXX9xoG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FMQi_zq93cQ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "DATA_SIZE=8000\n",
    "RADIUS=1.0\n",
    "EPOCHS=2000\n",
    "CHECKPOINT=250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "9K1BXW5o-Fz8",
    "outputId": "6a7fa9f3-dd1c-4b16-a34b-fc3fa8f85485"
   },
   "outputs": [],
   "source": [
    "def generate_unitary_circle_classif_data(nb_samples):\n",
    "    \"\"\"\n",
    "    Generates training data and labels:\n",
    "    Data: consists of points sampled from a 2D Gaussian.\n",
    "    Labels: there are two classes: \n",
    "                - 0 if the point is inside the unitary circle\n",
    "                - 1 otherwise\n",
    "    \"\"\"\n",
    "    data  = np.random.normal(size=(nb_samples, 2))\n",
    "    magnit = np.linalg.norm(data, ord=2, axis=-1)\n",
    "    labels = magnit > RADIUS\n",
    "    return data, labels\n",
    "\n",
    "def get_circle_segment(data, min_angle, max_angle):\n",
    "    \"\"\"\n",
    "    Returns a boolean array indicating which samples lay between min_angle and max_angle\n",
    "    \"\"\"\n",
    "    angles = get_angles(data)\n",
    "    return np.logical_and(min_angle < angles, angles < max_angle)\n",
    "    \n",
    "def get_angles(data):\n",
    "    \"\"\"\n",
    "    Compute the angle of each point stored in data\n",
    "    \"\"\"\n",
    "    return np.arctan2( data[:,0], data[:,1] )\n",
    "\n",
    "\n",
    "#generate random data\n",
    "data, labels = generate_unitary_circle_classif_data(DATA_SIZE)\n",
    "angles = get_angles(data)\n",
    "\n",
    "Q34 = get_circle_segment( data, -1*math.pi, 0 )\n",
    "Q12 = get_circle_segment( data, 0, math.pi )\n",
    "\n",
    "data_Q34 = data[Q34,:]\n",
    "data_Q12 = data[Q12,:]\n",
    "\n",
    "labels_Q34 = labels[Q34].astype('int').reshape(-1,1)\n",
    "labels_Q12 = labels[Q12].astype('int').reshape(-1,1)\n",
    "\n",
    "angles_Q34 = angles[Q34]\n",
    "angles_Q12 = angles[Q12]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "o9o2gFZW-vpB",
    "outputId": "99a632cc-2b59-4ea9-c24e-972dd606ded3"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(data_Q12[:,0],data_Q12[:,1],c=\"g\",label='Q12')\n",
    "plt.scatter(data_Q34[:,0],data_Q34[:,1],c=\"b\",label='Q34')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "eHYSxUDRFnpH",
    "outputId": "30d4822b-17e5-45f6-e569-d4e09e8e6975"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(data_Q12[:,0],data_Q12[:,1],c=labels_Q12.reshape((-1,)))\n",
    "plt.scatter(data_Q34[:,0],data_Q34[:,1],c=labels_Q34.reshape((-1,)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_test_grid(min_val=-5, max_val=5):\n",
    "    \"\"\"\n",
    "    Generate a grid for testing on the whole space\n",
    "    \"\"\"\n",
    "    lsp = np.linspace(min_val, max_val)\n",
    "    x, y = np.meshgrid(lsp, lsp)\n",
    "    grid = np.vstack((x.flatten(), y.flatten())).transpose()\n",
    "    \n",
    "    magnit = np.linalg.norm( grid, ord=2, axis=-1 )\n",
    "    labels = magnit > RADIUS\n",
    "    labels = labels.astype('int').reshape(-1,1)\n",
    "    \n",
    "    angles = get_angles(grid)\n",
    "        \n",
    "    return grid, labels, angles\n",
    "\n",
    "grid_data, grid_labels, grid_angles = generate_test_grid(min_val=-5,max_val=5)\n",
    "nb_grid_samples, _ = grid_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SZ_k02TK3O0"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "batch_size  = 1024\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcxiOTn6K_Sy"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "simple_train_set = TensorDataset(torch.from_numpy(data_Q34).float(), torch.from_numpy(labels_Q34))\n",
    "simple_valid_set = TensorDataset(torch.from_numpy(grid_data).float(), torch.from_numpy(grid_labels))\n",
    "\n",
    "simple_train_loader = DataLoader(simple_train_set, batch_size=batch_size, shuffle=True)\n",
    "simple_valid_loader = DataLoader(simple_valid_set, batch_size=nb_grid_samples, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "k519HNryJ0Dk",
    "outputId": "f5a286d4-4610-4933-adf7-36f4ab4227f5"
   },
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sig    = nn.Sigmoid()\n",
    "        \n",
    "        self.layer1 = nn.Linear(2,hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size,hidden_size)\n",
    "        \n",
    "        self.decision = nn.Linear(hidden_size,2)\n",
    "    \n",
    "    def forward(self, coord):\n",
    "        h = self.layer1(coord)\n",
    "        h = self.sig(h)\n",
    "        h = self.layer2(h)\n",
    "        h = self.sig(h)\n",
    "        h = self.layer3(h)\n",
    "        h = self.sig(h)\n",
    "        out = self.decision(h)\n",
    "        return out\n",
    "\n",
    "simple_model = SimpleClassifier()\n",
    "simple_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "OGclEBxMUMZM",
    "outputId": "f1940043-37df-465d-9081-09e015375691"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_mesh(model, loader):\n",
    "    \"\"\"\n",
    "    Plot the model predictions on the validation grid\n",
    "    \"\"\" \n",
    "    fig, ax = plt.subplots(ncols=2)\n",
    "    model.eval()\n",
    "    for x, y in loader:\n",
    "        y_scores = model(Variable(x))\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        points = ax[0].scatter( x.numpy()[:,0], x.numpy()[:,1], c=y.numpy().reshape(-1,),  s=10 )\n",
    "        points = ax[1].scatter( x.numpy()[:,0], x.numpy()[:,1], c=y_pred.numpy(),  s=10 )\n",
    "          \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[0].add_artist(circle)\n",
    "    ax[0].axis('equal')\n",
    "    ax[0].set_title(\"Gold Labels\")\n",
    "    ax[0].set_xlabel(\"x1\")\n",
    "    ax[0].set_ylabel(\"x2\")\n",
    "    \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[1].add_artist(circle)\n",
    "    ax[1].axis('equal')\n",
    "    ax[1].set_title(\"Predicted Labels\")\n",
    "    ax[1].set_xlabel(\"x1\")\n",
    "    ax[1].set_ylabel(\"x2\")\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "plot_mesh(simple_model, simple_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2036
    },
    "colab_type": "code",
    "id": "mGQZwL44Oz-c",
    "outputId": "3c3ba7e5-6916-4ba6-d789-afcaa4a3db0e"
   },
   "outputs": [],
   "source": [
    "def perf(model, loader):\n",
    "    \"\"\"\n",
    "    Compute loss and accuracy on a dataset \n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    total_loss = num = oks = 0\n",
    "    for x, y in loader:\n",
    "        y_scores = model(Variable(x))\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        \n",
    "        loss = criterion(y_scores.view(y.size(0), -1), Variable(y.view(y.size(0))))\n",
    "        total_loss += loss.data\n",
    "        num += len(y)\n",
    "        oks += torch.sum((y_pred.data == y.reshape(-1,)))\n",
    "        \n",
    "    return total_loss / num, math.exp(total_loss / num), float(oks)/float(num)\n",
    "\n",
    "\n",
    "def fit(model, train_loader, valid_loader, epochs):\n",
    "    \"\"\"\n",
    "    Train the model \n",
    "    \"\"\"    \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_scores = model(Variable(x))\n",
    "            loss = criterion(y_scores.view(y.size(0), -1), Variable(y.view(y.size(0))))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data\n",
    "            num += len(y)\n",
    "            \n",
    "        if((epoch+1)%CHECKPOINT == 0):\n",
    "            print(epoch+1, total_loss / num, *perf(model, valid_loader))\n",
    "\n",
    "\n",
    "fit(simple_model, simple_train_loader, simple_valid_loader, EPOCHS)        \n",
    "plot_mesh(simple_model, simple_valid_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Domain Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "iruG8SgqaO4d",
    "outputId": "b690425b-55ad-4ec1-baec-f749e8706a9e"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class GradReverse(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg()\n",
    "\n",
    "def grad_reverse(x):\n",
    "    return GradReverse.apply(x)\n",
    "  \n",
    "  \n",
    "\n",
    "class AdversarialClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The previous three layer neural network + adversarial network\n",
    "    \"\"\" \n",
    "    def __init__(self, nb_outs=2):\n",
    "        super().__init__()\n",
    "        self.sig     = nn.Sigmoid()\n",
    "        self.nb_outs = nb_outs\n",
    "        \n",
    "        self.layer1 = nn.Linear(2,hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size,hidden_size)\n",
    "        \n",
    "        self.decision = nn.Linear(hidden_size,2)\n",
    "        self.adversarial = nn.Linear(hidden_size, self.nb_outs)\n",
    "    \n",
    "    def forward(self, coord):\n",
    "        h = self.layer1(coord)\n",
    "        h = self.sig(h)\n",
    "        h = self.layer2(h)\n",
    "        h = self.sig(h)\n",
    "        h = self.layer3(h)\n",
    "        h = self.sig(h)\n",
    "        \n",
    "        out = self.decision(h)\n",
    "        \n",
    "        adv = grad_reverse(h)\n",
    "        adv = self.adversarial(adv)\n",
    "        \n",
    "        return out, adv\n",
    "\n",
    "\n",
    "adversarial_classif_model = AdversarialClassifier()\n",
    "adversarial_classif_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYfZcl96b2ST"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_simple_bi_domain_small_adv_labels(data):\n",
    "    \"\"\"\n",
    "    Generate a grid for testing on the whole space\n",
    "    \"\"\"\n",
    "    Q34   = get_circle_segment( data, -1*math.pi    , 0.0 )\n",
    "    Q34_1 = get_circle_segment( data, -1*math.pi    , -1*math.pi/2.0 )\n",
    "    Q34_2 = get_circle_segment( data, -1*math.pi/2.0, 0.0 )\n",
    "    \n",
    "    nb_samples, _ = data.shape\n",
    "    domain_labels = np.zeros((nb_samples,1))\n",
    "    domain_labels[Q34_1] = 0\n",
    "    domain_labels[Q34_2] = 1\n",
    "    \n",
    "    return domain_labels.astype('int').reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "grid_domain = get_simple_bi_domain_small_adv_labels(grid_data)\n",
    "data_domain = get_simple_bi_domain_small_adv_labels(data)\n",
    "\n",
    "# make the data loaders\n",
    "adv_classif_maintask_train_set = TensorDataset(torch.from_numpy(data_Q34).float(), torch.from_numpy(labels_Q34))\n",
    "adv_classif_advtask_train_set  = TensorDataset(torch.from_numpy(data).float(), torch.from_numpy(data_domain))\n",
    "\n",
    "adv_classif_maintask_loader = DataLoader(adv_classif_maintask_train_set, batch_size=batch_size, shuffle=True)\n",
    "adv_classif_advtask_loader  = DataLoader(adv_classif_advtask_train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "adv_classif_valid_set = TensorDataset(torch.from_numpy(grid_data).float(), torch.from_numpy(grid_labels), torch.from_numpy(grid_domain))\n",
    "adv_classif_valid_loader = DataLoader(adv_classif_valid_set, batch_size=nb_grid_samples, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1788
    },
    "colab_type": "code",
    "id": "UadAEwAUcbLw",
    "outputId": "7631f44f-878c-4c3d-da0b-5fe75d5795ae"
   },
   "outputs": [],
   "source": [
    "\n",
    "def perf_adv_classif(model, loader):\n",
    "    \"\"\"\n",
    "    Compute loss and accuracy on a dataset \n",
    "    **ignores the aversarial task\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    y_total_loss = d_total_loss = num = y_oks = d_oks = 0\n",
    "    for x, y, d in loader:\n",
    "        y_scores, d_scores = model(Variable(x))\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        d_pred = torch.max(d_scores, 1)[1]\n",
    "        \n",
    "        loss = criterion(y_scores.view(y.size(0), -1), Variable(y.view(y.size(0))))\n",
    "        y_total_loss += loss.data\n",
    "        \n",
    "        \n",
    "        loss = criterion(d_scores.view(d.size(0), -1), Variable(d.view(d.size(0))))\n",
    "        d_total_loss += loss.data\n",
    "        \n",
    "        num += len(y)\n",
    "        y_oks += torch.sum((y_pred.data == y.reshape(-1,)))\n",
    "        d_oks += torch.sum((d_pred.data == d.reshape(-1,)))\n",
    "        \n",
    "    return \"Y_LOSS:\", y_total_loss / num, \"Y_ACC:\", float(y_oks)/float(num), \"D_LOSS:\", d_total_loss / num, \"D_ACC:\", float(d_oks)/float(num)\n",
    "  \n",
    "\n",
    "\n",
    "def fit_adv_classif(model, main_loader, adv_loader, valid_loader, epochs):\n",
    "    \"\"\"\n",
    "    Train the adversarial model \n",
    "    \"\"\"    \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    adv_loader_epoch = iter(adv_loader)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        # iterate over batches\n",
    "        for (x, y) in main_loader:\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            # update lambda and learning rate to ensure stability\n",
    "            p = float(epoch) / epochs\n",
    "            lambd = 3. / (1. + np.exp(-5. * p)) - 1\n",
    "        \n",
    "            # exit if batch size incorrect, get next target batch\n",
    "            if len(x) < batch_size:\n",
    "                continue\n",
    "        \n",
    "            xt, dt = next(adv_loader_epoch)\n",
    "            if len(xt) < batch_size:\n",
    "                adv_loader_epoch = iter(adv_loader)\n",
    "                continue      \n",
    "\n",
    "            y_scores, _ = model(x)\n",
    "            _, adv_dt   = model(xt)\n",
    "\n",
    "            \n",
    "            main_loss = criterion(y_scores.view(y.size(0), -1), Variable(y.view(y.size(0))))\n",
    "            adv_loss  = criterion(adv_dt.view(dt.size(0), -1), Variable(dt.view(dt.size(0))))\n",
    "\n",
    "            loss = main_loss + lambd*(adv_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data\n",
    "            num += len(y)\n",
    "            \n",
    "        if((epoch+1)%CHECKPOINT == 0):\n",
    "            print(epoch+1, lambd, total_loss / num, *perf_adv_classif(model, valid_loader))      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fit_adv_classif(adversarial_classif_model, adv_classif_maintask_loader, \n",
    "                adv_classif_advtask_loader, adv_classif_valid_loader, EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "5-RohUa7xc1L",
    "outputId": "f9761a2e-a840-45b3-db35-1e412d793f90"
   },
   "outputs": [],
   "source": [
    "def plot_adv_classif_mesh(model, loader):\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=2,nrows=2)\n",
    "    model.eval()\n",
    "    for x, y, d in loader:\n",
    "        y_scores, d_scores = model(Variable(x))\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        d_pred = torch.max(d_scores, 1)[1]\n",
    "        \n",
    "        ax[0][0].scatter( x.numpy()[:,0], x.numpy()[:,1], c=y.numpy().reshape(-1), s=10 )\n",
    "        ax[0][1].scatter( x.numpy()[:,0], x.numpy()[:,1], c=y_pred.numpy(), s=10 )\n",
    "        ax[1][0].scatter( x.numpy()[:,0], x.numpy()[:,1], c=d.numpy().reshape(-1), s=10 )\n",
    "        ax[1][1].scatter( x.numpy()[:,0], x.numpy()[:,1], c=d_pred.numpy(), s=10 )\n",
    "        \n",
    "        \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[0][0].add_artist(circle)\n",
    "    ax[0][0].axis('equal')\n",
    "    ax[0][0].axvline(x=0)\n",
    "    ax[0][0].axhline(y=0)\n",
    "    ax[0][0].set_title(\"Gold Labels\")\n",
    "    ax[0][0].set_xlabel(\"x1\")\n",
    "    ax[0][0].set_ylabel(\"x2\")\n",
    "    \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[1][0].add_artist(circle)\n",
    "    ax[1][0].axis('equal')\n",
    "    ax[1][0].axvline(x=0)\n",
    "    ax[1][0].axhline(y=0)\n",
    "    ax[1][0].set_title(\"Gold Adversarial\")\n",
    "    ax[1][0].set_xlabel(\"x1\")\n",
    "    ax[1][0].set_ylabel(\"x2\")\n",
    "    \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[0][1].add_artist(circle)\n",
    "    ax[0][1].axis('equal')\n",
    "    ax[0][1].axvline(x=0)\n",
    "    ax[0][1].axhline(y=0)\n",
    "    ax[0][1].set_title(\"Predicted Labels\")\n",
    "    ax[0][1].set_xlabel(\"x1\")\n",
    "    ax[0][1].set_ylabel(\"x2\")\n",
    "\n",
    "    \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[1][1].add_artist(circle)\n",
    "    ax[1][1].axis('equal')\n",
    "    ax[1][1].axvline(x=0)\n",
    "    ax[1][1].axhline(y=0)\n",
    "    ax[1][1].set_title(\"Predicted Adversarial\")\n",
    "    ax[1][1].set_xlabel(\"x1\")\n",
    "    ax[1][1].set_ylabel(\"x2\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_adv_classif_mesh(adversarial_classif_model, adv_classif_valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Regression\n",
    "\n",
    "Here we train a model that adversarily predicts the angle of each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdversarialRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    The previous three layer neural network + adversarial network\n",
    "    \"\"\" \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sig    = nn.Sigmoid()\n",
    "        \n",
    "        self.layer1 = nn.Linear(2,hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size,hidden_size)\n",
    "        \n",
    "        self.decision = nn.Linear(hidden_size,2)\n",
    "        self.adversarial = nn.Linear(hidden_size,1)\n",
    "    \n",
    "    def forward(self, coord):\n",
    "        h = self.layer1(coord)\n",
    "        h = self.sig(h)\n",
    "        h = self.layer2(h)\n",
    "        h = self.sig(h)\n",
    "        h = self.layer3(h)\n",
    "        h = self.sig(h)\n",
    "        \n",
    "        out = self.decision(h)\n",
    "        \n",
    "        adv = grad_reverse(h)\n",
    "        adv = self.adversarial(adv)\n",
    "        #adv = self.adversarial(h)\n",
    "        \n",
    "        return out, adv\n",
    "\n",
    "adversarial_regress_model = AdversarialRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perf_adv_regressor(model, loader):\n",
    "    \"\"\"\n",
    "    Compute loss and accuracy on a dataset \n",
    "    **ignores the aversarial task\n",
    "    \"\"\"\n",
    "    criterion_classif = nn.CrossEntropyLoss()\n",
    "    criterion_regress = nn.MSELoss()\n",
    "    model.eval()\n",
    "    total_loss = num = oks = mse = 0\n",
    "    for x, y, d in loader:\n",
    "        y_scores, d_reg = model(Variable(x))\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        \n",
    "        loss = criterion_classif(y_scores.view(y.size(0), -1), Variable(y.view(y.size(0))))\n",
    "        mse += criterion_regress(d_reg, Variable(d))\n",
    "        total_loss += loss.data\n",
    "        num += len(y)\n",
    "        oks += torch.sum((y_pred.data == y.reshape(-1,)))\n",
    "        \n",
    "    return \"Y_LOSS:\", total_loss / num, \"Y_ACC:\", float(oks)/float(num), \"D_LOSS:\", mse / num\n",
    "\n",
    "\n",
    "def fit_adv_regressor(model, main_loader, adv_loader, valid_loader, epochs):\n",
    "    \"\"\"\n",
    "    Train the adversarial model \n",
    "    \"\"\"    \n",
    "\n",
    "    criterion_classif = nn.CrossEntropyLoss()\n",
    "    criterion_regress = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    adv_loader_epoch = iter(adv_loader)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        # iterate over batches\n",
    "        for (x, y) in main_loader:\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            # update lambda and learning rate to ensure stability\n",
    "            p = float(epoch) / epochs\n",
    "            \n",
    "            if( epoch < 10 ):\n",
    "                lambd = 0.0\n",
    "            else:\n",
    "                lambd = 3. / (1. + np.exp(-1.0 * p)) - 1\n",
    "            \n",
    "            \n",
    "            # exit if batch size incorrect, get next target batch\n",
    "            if len(x) < batch_size:\n",
    "                continue\n",
    "        \n",
    "            xt, dt = next(adv_loader_epoch)\n",
    "            if len(xt) < batch_size:\n",
    "                adv_loader_epoch = iter(adv_loader)\n",
    "                continue      \n",
    "\n",
    "            y_scores, _ = model(x)\n",
    "            _, adv_dt   = model(xt)\n",
    "\n",
    "            main_loss = criterion_classif(y_scores.view(y.size(0), -1), Variable(y.view(y.size(0))))\n",
    "            adv_loss  = criterion_regress(adv_dt.view(adv_dt.size(0), -1), Variable(dt).view(adv_dt.size(0), -1))\n",
    "\n",
    "            loss = main_loss + lambd*(adv_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data\n",
    "            num += len(dt)\n",
    "            \n",
    "        if((epoch+1)%CHECKPOINT == 0):\n",
    "            print(epoch+1, lambd, total_loss / num, *perf_adv_regressor(model, valid_loader))      \n",
    "\n",
    "    \n",
    "# make the data loaders\n",
    "adv_regress_maintask_train_set = TensorDataset(torch.from_numpy(data_Q34).float(), torch.from_numpy(labels_Q34))\n",
    "adv_regress_advtask_train_set  = TensorDataset(torch.from_numpy(data).float(), torch.from_numpy(angles).float())\n",
    "\n",
    "adv_regress_maintask_loader = DataLoader(adv_regress_maintask_train_set, batch_size=batch_size, shuffle=True)\n",
    "adv_regress_advtask_loader  = DataLoader(adv_regress_advtask_train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "adv_regress_valid_set = TensorDataset(torch.from_numpy(grid_data).float(), torch.from_numpy(grid_labels), torch.from_numpy(grid_angles).float())\n",
    "adv_regress_valid_loader = DataLoader(adv_regress_valid_set, batch_size=nb_grid_samples, shuffle=True)\n",
    "\n",
    "\n",
    "fit_adv_regressor(adversarial_regress_model, adv_regress_maintask_loader,\n",
    "                  adv_regress_advtask_loader, adv_regress_valid_loader, EPOCHS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def plot_adv_regress_mesh(model, loader):\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=2,nrows=2)\n",
    "    model.eval()\n",
    "    for x, y, d in loader:\n",
    "        y_scores, d_scores = model(Variable(x))\n",
    "        y_pred = torch.max(y_scores, 1)[1]\n",
    "        d_pred = d_scores.detach().numpy().reshape(-1,)\n",
    "        \n",
    "        ax[0][0].scatter( x.numpy()[:,0], x.numpy()[:,1], c=y.numpy().reshape(-1), s=10 )\n",
    "        ax[0][1].scatter( x.numpy()[:,0], x.numpy()[:,1], c=y_pred.numpy(), s=10 )\n",
    "        im10 = ax[1][0].scatter( x.numpy()[:,0], x.numpy()[:,1], c=(180.0/math.pi)*d.numpy().reshape(-1), s=10, vmin=-180, vmax=180 )\n",
    "        im11 = ax[1][1].scatter( x.numpy()[:,0], x.numpy()[:,1], c=(180.0/math.pi)*d_pred, s=10, vmin=-180, vmax=180 )\n",
    "        \n",
    "        \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[0][0].add_artist(circle)\n",
    "    ax[0][0].axis('equal')\n",
    "    \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[1][0].add_artist(circle)\n",
    "    ax[1][0].axis('equal')\n",
    "    plt.colorbar(im10, ax=ax[1][0])\n",
    "    #ax[1][0].colorbar()\n",
    "    \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[0][1].add_artist(circle)\n",
    "    ax[0][1].axis('equal')\n",
    "    \n",
    "    \n",
    "    circle = plt.Circle((0,0), RADIUS, color='r', fill=False, lw=3)\n",
    "    ax[1][1].add_artist(circle)\n",
    "    ax[1][1].axis('equal')\n",
    "    plt.colorbar(im11, ax=ax[1][1])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_adv_regress_mesh(adversarial_regress_model, adv_regress_valid_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldkDZMnlCs6Z"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "adversarial_learning(1).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
