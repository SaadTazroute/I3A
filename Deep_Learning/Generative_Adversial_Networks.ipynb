{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Generative_TP_Saad.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOMP0WoFBA5f"
      },
      "source": [
        "<h1> TP6: Generative Adversarial Networks</h1>\n",
        "\n",
        "Ce TP est consacré à la manipulation de réseaux génératifs exploitant le paradigme d'apprentissage \"Adversarial\". Ce type de réseaux comprend une partie \"Générateur\" et une autre \"Discriminateur\", chacun ayant des objectifs antagonistes. \n",
        "\n",
        "La première partie de ce TP illustre la capacité des GAN sur des données artificielles, sous la forme d'un mélange de gaussiennes 1D. Cette partie est fortement guidée et met en évidence la capacité des deux sous réseaux pour parvenir à approcher au mieux la distribution sous jacentes des données.\n",
        "\n",
        "La deuxième partie nécessite un travail en autonomie. Elle consiste à étendre le réseau préalablement définie pour, cette fois, modéliser la distribution des données issues du jeu de données MNIST (les chiffres manuscrits).\n",
        "\n",
        "Pour finir, vous pourriez vous amuser et générer des visages réalistes à partir du jeu de données CelebA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbvBt_nnAkmy"
      },
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmxGjvDdEYQh"
      },
      "source": [
        "<h2>Partie 1: GANs avec des données artificielles</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXC6phSxGnsE"
      },
      "source": [
        "Dans la cellule suivante, on créé des données artificielles à partir de distributions gaussiennes. Par la suite, on modifiera le code pour obtenir des données multimodales (ie: mélange de gaussinnes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trY9PDD1BZ19"
      },
      "source": [
        "batch_size = 10\n",
        "nbdata = 250\n",
        "data_dim = 1 # 1-dimensional data\n",
        "\n",
        "xdata = np.random.normal(5, 0.1, (nbdata, data_dim))\n",
        "#xdata1 = np.random.normal(5, 0.1, (int(nbdata/3), data_dim))\n",
        "#xdata2 = np.random.normal(10, 0.1, (int(nbdata/3), data_dim)) # for multimodal data\n",
        "#xdata3 = np.random.normal(15, 0.1, (int(nbdata/3), data_dim)) # for multimodal data\n",
        "#xdata = np.concatenate((xdata1, xdata2, xdata3), axis=0) # for multimodal data\n",
        "np.random.shuffle(xdata)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCcLBfnVItN5"
      },
      "source": [
        "Affichage de la densité de distribution correspondant à nos données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_UODM_hGADX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "43e665e8-eb87-4440-dbe8-243e922485b6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xs = np.linspace(0, 30, 10*batch_size)[:-1]\n",
        "bins = np.linspace(0, 30, 10*batch_size)\n",
        "hx,_ = np.histogram(xdata, bins=bins, density=True)\n",
        "plt.plot(xs, hx)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f994075ea10>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzwQ5LsBA8xZ"
      },
      "source": [
        "<h2>Création d'un générateur python pour accéder aux données par batch</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC3iMQ-FBD8g"
      },
      "source": [
        "def get_batch():\n",
        "  i = 0\n",
        "  while True:\n",
        "    i = i + batch_size\n",
        "    if i+batch_size > nbdata: i = 0\n",
        "    \n",
        "    yield xdata[i:i+batch_size].reshape((batch_size, data_dim))\n",
        "\n",
        "data_generator = get_batch()\n",
        "#x = next(data_generator)\n",
        "#print(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiZTmuPJFnVo"
      },
      "source": [
        "<h2> Création du réseau</h2>\n",
        "\n",
        "Ici nous créons les deux parties : \"générateur\" et \"discriminateur\", puis le modèle combiné \"GAN\". Réseaux très simples comprenant deux couches cachées denses avec tanh + une couche sortie. Dropout dans le discriminateur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7S2vsnPD1Sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8f5fdc-011e-45ee-b9e3-9139300a4f0b"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# some hyperparameters\n",
        "z_dim = 5\n",
        "h_dim = 10\n",
        "\n",
        "def generator(opt):\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(h_dim, activation=\"tanh\", input_shape=(z_dim,)))\n",
        "  model.add(keras.layers.Dense(int((h_dim+data_dim)/2), activation=\"tanh\", input_shape=(z_dim,)))\n",
        "  model.add(keras.layers.Dense(int((h_dim+data_dim)/2), activation=\"tanh\", input_shape=(z_dim,)))\n",
        "  model.add(keras.layers.Dense(data_dim))\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=opt)\n",
        "  return model\n",
        "\n",
        "opt = Adam(learning_rate=0.001, beta_1=0.5, beta_2=0.99)\n",
        "G = generator(opt)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEDn5vbWGhbT"
      },
      "source": [
        "def discriminator(opt):\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(h_dim, activation=\"tanh\", input_shape=(data_dim,)))\n",
        "  model.add(keras.layers.Dense(int(h_dim/2), activation=\"tanh\"))\n",
        "  model.add(keras.layers.Dense(int(h_dim/2), activation=\"tanh\"))\n",
        "  model.add(keras.layers.Dropout(0.4))\n",
        "  \n",
        "  model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=opt)\n",
        "  return model\n",
        "\n",
        "D = discriminator(opt)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JodZVqxoIE9E"
      },
      "source": [
        "def gan(opt):\n",
        "  D.trainable = False\n",
        "  GAN = keras.models.Sequential()\n",
        "  GAN.add(G)\n",
        "  GAN.add(D)\n",
        "  GAN.compile(loss=\"binary_crossentropy\", optimizer=opt)\n",
        "  return GAN\n",
        "\n",
        "GAN = gan(opt)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_WxueYAHZR4"
      },
      "source": [
        "<h2>Apprentissage du modèle</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WUCOvakHoJ6"
      },
      "source": [
        "Initialise des structures pour construire des plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K43xSgNUL15Y"
      },
      "source": [
        "xtab = []\n",
        "gtab = []\n",
        "lossDtab = []\n",
        "lossGtab = []\n",
        "Dpostab = []\n",
        "Dnegtab = []\n",
        " \n",
        "epochs_done = 0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGEV_6RgH_RT"
      },
      "source": [
        "Boucle d'apprentissage, alterne entre le discriminateur et le GAN. Enregistre les valeurs de loss du discriminateur (lossD) et du générateur (lossG), et es prédictions du discriminateur pour des exemples positifs (Dpos) et négatifs (Dneg). Conserve l'historique dans des listes pour affichage ultérieur. On enregistre aussi des données obtenues par le générateur à chaque epoch, ces données seront utilisées et animées dans une cellule suivante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMYbp-ndId01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0772ffcb-643b-4d18-a4ef-8f6e84ee0e0a"
      },
      "source": [
        "data_generator = get_batch()\n",
        "nb_epoch = 1000 #2000\n",
        "ones = np.ones((batch_size, 1))\n",
        "zeros = np.zeros((batch_size, 1))\n",
        "for epoch in range(nb_epoch):\n",
        "  lossD = []\n",
        "  lossG = []\n",
        "  Dpos = []\n",
        "  Dneg = []\n",
        "  for batch in range(int(nbdata/batch_size)):\n",
        "    # train discriminator with positive samples\n",
        "    x = next(data_generator)\n",
        "    lossP = D.train_on_batch(x, ones)\n",
        "    if epoch % 10 == 0:\n",
        "      x = next(data_generator)\n",
        "      Dpos.append( D.predict(x) )\n",
        "    \n",
        "    # train discriminator with negative samples\n",
        "    z = np.random.uniform(-1,1,(batch_size, z_dim))\n",
        "    fakes = G.predict(z)\n",
        "    lossN = D.train_on_batch(fakes, zeros)\n",
        "    if epoch % 10 == 0:\n",
        "      z = np.random.uniform(-1,1,(batch_size, z_dim))\n",
        "      fakes = G.predict(z)\n",
        "      Dneg.append( D.predict(fakes) )\n",
        "    \n",
        "    # compute D's loss (for plotting)\n",
        "    lossD.append((lossP + lossN) / 2.)\n",
        "    \n",
        "    # train generator with GAN\n",
        "    z = np.random.uniform(-1,1,(batch_size, z_dim))\n",
        "    lossG.append( GAN.train_on_batch(z, ones) )\n",
        "  \n",
        "  # Compute and store some statistics for further plotting\n",
        "  if epoch % 10 == 0:\n",
        "    lossD = np.mean(lossD)\n",
        "    lossG = np.mean(lossG)\n",
        "    Dpos = np.mean(Dpos)\n",
        "    Dneg = np.mean(Dneg)\n",
        "  \n",
        "    lossDtab.append(lossD)\n",
        "    lossGtab.append(lossG)\n",
        "    Dpostab.append(Dpos)\n",
        "    Dnegtab.append(Dneg)\n",
        "  \n",
        "    print(epoch, \" lossD=\", lossD, \" lossG=\", lossG, \" Dpos=\", Dpos, \" Dneg=\", Dneg )\n",
        "  \n",
        "  # Sample data from generator to plot an animation of learned distribution\n",
        "  z = np.random.uniform(-1,1,(10*batch_size, z_dim))\n",
        "  g = G.predict(z)\n",
        "  hg,_ = np.histogram(g, bins=bins, density=True)\n",
        "  gtab.append(hg)\n",
        "  xtab.append(hx)\n",
        "  \n",
        "  epochs_done = epochs_done + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  lossD= 0.5930288648605346  lossG= 0.7084615468978882  Dpos= 0.62186956  Dneg= 0.49200812\n",
            "10  lossD= 0.5398085075616836  lossG= 0.9192053818702698  Dpos= 0.6109112  Dneg= 0.40435627\n",
            "20  lossD= 0.8095503258705139  lossG= 0.5944685840606689  Dpos= 0.45137456  Dneg= 0.55294573\n",
            "30  lossD= 0.6563327240943909  lossG= 0.7801731371879578  Dpos= 0.49974954  Dneg= 0.45597273\n",
            "40  lossD= 0.6650525856018067  lossG= 0.6661829924583436  Dpos= 0.54594344  Dneg= 0.5158094\n",
            "50  lossD= 0.6912890219688416  lossG= 0.7033195114135742  Dpos= 0.49842995  Dneg= 0.4941855\n",
            "60  lossD= 0.6904788994789124  lossG= 0.6927333426475525  Dpos= 0.5024468  Dneg= 0.502997\n",
            "70  lossD= 0.6939481782913208  lossG= 0.6985371923446655  Dpos= 0.499012  Dneg= 0.498026\n",
            "80  lossD= 0.6930438899993896  lossG= 0.6922775769233703  Dpos= 0.5018464  Dneg= 0.50088286\n",
            "90  lossD= 0.6951159429550171  lossG= 0.6991577744483948  Dpos= 0.49700925  Dneg= 0.4965747\n",
            "100  lossD= 0.6920255565643311  lossG= 0.6932205843925476  Dpos= 0.5012281  Dneg= 0.500418\n",
            "110  lossD= 0.6946287035942078  lossG= 0.7047430562973023  Dpos= 0.49642175  Dneg= 0.49566796\n",
            "120  lossD= 0.6952963972091675  lossG= 0.6942778110504151  Dpos= 0.50014746  Dneg= 0.49946773\n",
            "130  lossD= 0.6945976781845092  lossG= 0.6998922443389892  Dpos= 0.4998507  Dneg= 0.4989216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPKHbkIUFHis"
      },
      "source": [
        "<h2>Création et affichage des plots</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTaMOb51DL90"
      },
      "source": [
        "<b>1. Evolution des prédictions du discriminateur sur les données réelles (en bleu) ou sur les données fournies par le générateur (en vert).</b>\n",
        "On observe une convergence rapide vers 0.5, le point d'équilibre lorsque le discriminateur ne sait plus distinguer l'origine des données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpiz98dWJCPE"
      },
      "source": [
        "ppos, = plt.plot(Dpostab, label=\"pos\")\n",
        "pneg, = plt.plot(Dnegtab, label=\"neg\")\n",
        "plt.legend(handles=[ppos, pneg])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQl8u17pF7D_"
      },
      "source": [
        "<b>2. Evolution des données obtenues au cours de l'apprentissage.</b>\n",
        "Selon le nombre d'epochs, la cellule suivante prend un peu de temps pour construire un gif que nous affichons dans la foulée. Cette étape nécessite l'installation du package ffmeg-python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlGZCTOJemuW"
      },
      "source": [
        "#!pip install ffmpeg-python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "ax.set_xlim((0,30))\n",
        "ax.set_ylim((0, 4))\n",
        "\n",
        "px, = ax.plot([], [], lw=2)\n",
        "pg, = ax.plot([], [], lw=2)\n",
        "\n",
        "def init():\n",
        "  px.set_data([],[])\n",
        "  pg.set_data([],[])\n",
        "  return (px, pg)\n",
        "\n",
        "def animate(i):\n",
        "  px.set_data(xs, xtab[i*10])\n",
        "  pg.set_data(xs, gtab[i*10])\n",
        "  return (px, pg)\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=int(epochs_done/10), blit=True)\n",
        "rc('animation', html='jshtml')\n",
        "anim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0oqmjFyFqxO"
      },
      "source": [
        "<b>3. Comparaison entre un batch de données original et de données issues du générateur.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIgYgIlrNATA"
      },
      "source": [
        "# get a batch of real data (for comparison)\n",
        "x = next(data_generator)\n",
        "print(\"some real data:\", x)\n",
        "\n",
        "# sample some noise then transform them with our generator\n",
        "z = np.random.uniform(-1,1,(10*batch_size, z_dim))\n",
        "g = G.predict(z)\n",
        "print(\"some generated data\", g[:10])\n",
        "\n",
        "# plot distributions\n",
        "xs = np.linspace(0, 30, 10*batch_size)[:-1]\n",
        "bins = np.linspace(0, 30, 10*batch_size)\n",
        "\n",
        "hg,_ = np.histogram(g, bins=bins, density=True)\n",
        "plt.plot(xs,hg)\n",
        "\n",
        "hx,_ = np.histogram(x, bins=bins, density=True)\n",
        "plt.plot(xs,hx)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz58kXUPD2jM"
      },
      "source": [
        "# Travail à faire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dvOBngcJ4j-"
      },
      "source": [
        "1. Modifiez la première fonction de création de données pour obtenir la moitiée de données centrées autour de 5 et l'autre autour de 10. La distribution de probabilité associée à ces données est dite \"multimodale\" (2 modes). \n",
        "\n",
        "2. Réinitialisez les modèles et relancez l'apprentissage. Essayez plus d'epoch si besoin. \n",
        "\n",
        "3. Augmentez les capacités du discriminateur et générateur en augmentant leur nombre de neurones dans les couches cachées.\n",
        "\n",
        "4. Augmentez de nouveau le nombre de modes de la distribution de données et retentez l'expérience. La difficulté de parvenir à apprendre des distributions multimodales correspond au \"mode collapse\" dans la littérature GAN. Une manière de contourner ce problème consiste à encourager le discriminateur à reconnaitre une diversité dans un batch d'exemples. Plusieurs approches ont été proposées dans ce sens, dont \"batch discrimination\" et \"standard deviation discrimination\" (à voir dans la littérature)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTozUrlAK23A"
      },
      "source": [
        "<h2>Partie 2: GANs sur MNIST</h2>\n",
        "\n",
        "Cette partie se déroule en totale autonomie.. Une fois bien compris la partie précédente, proposez un réseau adversarial pour générer des chiffres manuscrits (et/ou des visages pour les très motivés). \n",
        "\n",
        "Selon la nature et la structure des données, les réseaux \"générateur\" et \"discriminateur\" pourront exploiter des couches convolutionnelles, batch_discrimination ou dropout. Attention les couches Batch Discrimination et Dropout se comportent différemment lorsqu'elle sont utilisées en phase d'apprentissage ou d'inférence. Or, le discriminateur utilisé par le modèle combiné \"GAN\" est en mode \"inférence\" étant donné qu'il est configuré pour ne pas apprendre. Dans ce cas, avec Keras il est nécessaire de préciser <i>training=True</i> à l'initialisation de ces couches.\n",
        "\n",
        "Pour MNIST, nous considéront que le générateur prend en entrée un vecteur aléatoire de dimension 10, puis augmentera la taille des représentation jusqu'aux images ciblées (ie 28x28 pour MNIST) par l'emploi successifs de :\n",
        "- couches Denses de tailles adéquates (ie: 10 - 100 - 400 - 784), en augmentant le nombre de neurones, puis en utilisant la couche Reshape avant la sortie.\n",
        "- couches Conv2D couplées avec des couches UpSampling ; ou Conv2DTranspose. Toujours en augmentant progressivement la taille des représentation."
      ]
    }
  ]
}