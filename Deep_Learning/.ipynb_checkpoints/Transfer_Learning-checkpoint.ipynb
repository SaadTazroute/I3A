{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOMP0WoFBA5f"
   },
   "source": [
    "<h1> TP transfert - Deep Learning </h1>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "<b>N'envoyez pas votre travail par mail :</b>\n",
    "- Zippez votre fichier notebook, et nommez l'archive avec votre nom\n",
    "- Envoyez l'archive via la page :  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/upload/upload.php\n",
    "\n",
    "<hr/>\n",
    "\n",
    "Un musée spécialisé en peintures représentant des animaux de la savane a malheureusement perdu son fichier d'inventaire qui regroupait des informations précieuses sur les 2000 oeuvres du musée ! Fort heureusement, l'informaticien toujours prévoyant avait conservé une copie des 2000 photos des oeuvres, et il vient juste de suivre une formation de Deep Learning ...\n",
    "\n",
    "<center>\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/0.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/1.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/2.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/3.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/4.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/5.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/6.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/7.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/8.jpg\" width=\"90px\" />\n",
    "<img src=\"https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/9.jpg\" width=\"90px\" />\n",
    "</center>\n",
    "\n",
    "Cet examen porte sur la résolution d'une tâche de classification d'images sur un jeu de données faiblement annoté. Plusieurs solutions sont envisagées  consistant à tirer parti d'annotations de classes équivalentes sur un autre dataset entièrement étiquetté (imagenet). Les deux jeux de données contiennent 2000 images réparties (également) en quatre classes (d'animaux : zèbres, gorilles, léopards, tigres). 1500 images sont utilisées pour l'entrainement, 500 pour l'évaluation. Seul le jeu de données A (imagenet) est complètement annoté, le dataset B (les photos des oeuvres du musée) ne contient que très peu d'annotations.\n",
    "\n",
    "La partie 1 consiste à entrainer et évaluer les performances d'un modèle CNN fourni sur les deux datasets d'images. Les parties 2 et 3 consistent à mettre en oeuvre deux solutions par <i>adaptation de domaines</i> pour tenter d'améliorer les performances de classification sur le dataset faiblement annoté. Vous pouvez consacrer environ une heure à chaque partie, notées également.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhEFJi2Jm-AU"
   },
   "source": [
    "<h3> Téléchargement des données </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xOoNnEmRXA0O",
    "outputId": "1edaebdc-ca11-4c3a-aed0-a7bd8ed261c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-07 23:54:05--  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/imagenetXtrain.npy\n",
      "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18432128 (18M)\n",
      "Saving to: ‘imagenetXtrain.npy’\n",
      "\n",
      "imagenetXtrain.npy  100%[===================>]  17.58M  37.6MB/s    in 0.5s    \n",
      "\n",
      "2021-11-07 23:54:06 (37.6 MB/s) - ‘imagenetXtrain.npy’ saved [18432128/18432128]\n",
      "\n",
      "--2021-11-07 23:54:06--  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/imagenetYtrain.npy\n",
      "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12128 (12K)\n",
      "Saving to: ‘imagenetYtrain.npy’\n",
      "\n",
      "imagenetYtrain.npy  100%[===================>]  11.84K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-07 23:54:06 (111 MB/s) - ‘imagenetYtrain.npy’ saved [12128/12128]\n",
      "\n",
      "--2021-11-07 23:54:06--  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/imagenetXtest.npy\n",
      "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6144128 (5.9M)\n",
      "Saving to: ‘imagenetXtest.npy’\n",
      "\n",
      "imagenetXtest.npy   100%[===================>]   5.86M  21.5MB/s    in 0.3s    \n",
      "\n",
      "2021-11-07 23:54:06 (21.5 MB/s) - ‘imagenetXtest.npy’ saved [6144128/6144128]\n",
      "\n",
      "--2021-11-07 23:54:07--  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/imagenetYtest.npy\n",
      "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4128 (4.0K)\n",
      "Saving to: ‘imagenetYtest.npy’\n",
      "\n",
      "imagenetYtest.npy   100%[===================>]   4.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-07 23:54:07 (160 MB/s) - ‘imagenetYtest.npy’ saved [4128/4128]\n",
      "\n",
      "--2021-11-07 23:54:07--  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/awaXtrain.npy\n",
      "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18432128 (18M)\n",
      "Saving to: ‘awaXtrain.npy’\n",
      "\n",
      "awaXtrain.npy       100%[===================>]  17.58M  38.0MB/s    in 0.5s    \n",
      "\n",
      "2021-11-07 23:54:07 (38.0 MB/s) - ‘awaXtrain.npy’ saved [18432128/18432128]\n",
      "\n",
      "--2021-11-07 23:54:07--  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/awaYtrain.npy\n",
      "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 528\n",
      "Saving to: ‘awaYtrain.npy’\n",
      "\n",
      "awaYtrain.npy       100%[===================>]     528  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-07 23:54:07 (32.2 MB/s) - ‘awaYtrain.npy’ saved [528/528]\n",
      "\n",
      "--2021-11-07 23:54:07--  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/awaXtest.npy\n",
      "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6144128 (5.9M)\n",
      "Saving to: ‘awaXtest.npy’\n",
      "\n",
      "awaXtest.npy        100%[===================>]   5.86M  21.8MB/s    in 0.3s    \n",
      "\n",
      "2021-11-07 23:54:08 (21.8 MB/s) - ‘awaXtest.npy’ saved [6144128/6144128]\n",
      "\n",
      "--2021-11-07 23:54:08--  https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/awaYtest.npy\n",
      "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
      "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4128 (4.0K)\n",
      "Saving to: ‘awaYtest.npy’\n",
      "\n",
      "awaYtest.npy        100%[===================>]   4.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-07 23:54:08 (179 MB/s) - ‘awaYtest.npy’ saved [4128/4128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/imagenetXtrain.npy\n",
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/imagenetYtrain.npy\n",
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/imagenetXtest.npy\n",
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/imagenetYtest.npy\n",
    "  \n",
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/awaXtrain.npy\n",
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/awaYtrain.npy\n",
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/awaXtest.npy\n",
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/TP_transfer/awaYtest.npy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JELpwwuImeSc"
   },
   "source": [
    "<h3>Chargement des données</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fbvBt_nnAkmy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Flatten, LeakyReLU\n",
    "from keras.layers import AveragePooling2D, Conv2D, Activation, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import utils as np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHDrGe_IYIUm",
    "outputId": "52121191-4572-47ba-d10e-4b076b7042dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_trainA.shape: (1500, 64, 64, 3) y_trainA.shape: (1500, 4)\n",
      "x_trainB.shape: (1500, 64, 64, 3) y_trainB.shape: (50, 4)\n",
      "x_testA.shape: (500, 64, 64, 3) y_testA.shape: (500, 4)\n",
      "x_testB.shape: (500, 64, 64, 3) y_testB.shape: (500, 4)\n"
     ]
    }
   ],
   "source": [
    "path = './'\n",
    "num_classes = 4\n",
    "\n",
    "x_trainA = np.load(path+'imagenetXtrain.npy')\n",
    "x_trainA = x_trainA / 255.\n",
    "y_trainA = np.load(path+'imagenetYtrain.npy')\n",
    "y_trainA = keras.utils.to_categorical(y_trainA, num_classes)\n",
    "\n",
    "x_testA = np.load(path+'imagenetXtest.npy')\n",
    "x_testA = x_testA / 255.\n",
    "y_testA = np.load(path+'imagenetYtest.npy')\n",
    "y_testA = keras.utils.to_categorical(y_testA, num_classes)\n",
    "\n",
    "x_trainB = np.load(path+'awaXtrain.npy')\n",
    "x_trainB = x_trainB / 255.\n",
    "y_trainB = np.load(path+'awaYtrain.npy')\n",
    "y_trainB = keras.utils.to_categorical(y_trainB, num_classes)\n",
    "\n",
    "x_testB = np.load(path+'awaXtest.npy')\n",
    "x_testB = x_testB / 255.\n",
    "y_testB = np.load(path+'awaYtest.npy')\n",
    "y_testB = keras.utils.to_categorical(y_testB, num_classes)\n",
    "\n",
    "print('x_trainA.shape:', x_trainA.shape, 'y_trainA.shape:', y_trainA.shape)\n",
    "print('x_trainB.shape:', x_trainB.shape, 'y_trainB.shape:', y_trainB.shape)\n",
    "\n",
    "print('x_testA.shape:', x_testA.shape, 'y_testA.shape:', y_testA.shape)\n",
    "print('x_testB.shape:', x_testB.shape, 'y_testB.shape:', y_testB.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwLsluNtYHkG"
   },
   "source": [
    "Les deux jeux de données contiennent 2000 images, de 64x64x3 pixels, réparties en quatre classes. 1500 images sont utilisées pour l'entrainement, 500 pour l'évaluation. Seul le jeu de données A est complètement annoté, le jeu de donnée B ne contient que très peu d'annotations, correspondantent aux 50 premiers exemples de x_trainB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NRp44rQagA-"
   },
   "source": [
    "<h2> Partie 1 : Modèle convolutionnel pour la classification d'images </h2>\n",
    "\n",
    "On définie ci-dessous une architecture convolutionnelle simple, à ne pas modifier. Cette partie vise à évaluer la performance d'un modèle CNN sur les deux dataset A et B. Entrainez ce modèle des différentes manières possibles et reportez les performances obtenues dans le tableau situé en fin de cette partie. A chaque nouvel apprentissage, utilisez les configurations suivantes : \n",
    "- 30 epochs\n",
    "- Taille des minibatchs à 64\n",
    "- 10% des données pour validation\n",
    "\n",
    "Tracez les courbes d'apprentissage, et commentez vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVzDIs5-a_jI",
    "outputId": "3b2fb6f6-0f26-4d38-88a2-ae5b99400411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 4096)              1110784   \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         (None, 4)                 4722180   \n",
      "=================================================================\n",
      "Total params: 5,832,964\n",
      "Trainable params: 5,831,812\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Couches d'apprentissage de représentations par convolutions \n",
    "ximg = Input(shape=(x_trainA.shape[1], x_trainA.shape[2], x_trainA.shape[3]))\n",
    "\n",
    "l = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(ximg)\n",
    "l = BatchNormalization(axis=-1)(l)\n",
    "l = Activation('relu')(l)\n",
    "l = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(l)\n",
    "l = BatchNormalization(axis=-1)(l)\n",
    "l = Activation('relu')(l)\n",
    "l = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(l)\n",
    "l = BatchNormalization(axis=-1)(l)\n",
    "l = Activation('relu')(l)\n",
    "l = AveragePooling2D((4,4))(l)\n",
    "l = Conv2D(256, kernel_size=(3,3), strides=(2,2), padding='same')(l)\n",
    "l = BatchNormalization(axis=-1)(l)\n",
    "l = Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same')(l)\n",
    "l = AveragePooling2D((2,2))(l)\n",
    "l = Activation('relu')(l)\n",
    "l = Dropout(0.2)(l)\n",
    "feat_layer = Flatten()(l)\n",
    "\n",
    "# conv_model(ximg) retourne la couche 'feat_layer' : 4096 dimensions pour une image 64x64x3\n",
    "conv_model = Model(ximg, feat_layer) \n",
    "\n",
    "# Couches de classification\n",
    "xfeat = Input(shape=(4096,))\n",
    "y = Dense(1024, activation='relu')(xfeat)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense(512, activation='relu')(y)\n",
    "out_layer = Dense(num_classes, activation='softmax')(y)\n",
    "\n",
    "# classif_model(xfeat) renvoie la couche sortie du classifieur : 4 dimensions\n",
    "classif_model = Model(xfeat, out_layer) \n",
    "\n",
    "# Modèle CNN : représentation + classifier\n",
    "feat = conv_model(ximg)\n",
    "clf = classif_model(feat)\n",
    "model = Model(ximg, clf)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-0G5SHsaX06"
   },
   "source": [
    "<h4> Entrainement du modèle sur les données A, puis évaluation sur A et B</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GvEjDRqbNXm",
    "outputId": "bb6c781b-df77-47d8-cbe7-75fb84efe2ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22/22 [==============================] - 37s 232ms/step - loss: 1.3046 - accuracy: 0.4044 - val_loss: 1.3820 - val_accuracy: 0.3067\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.9797 - accuracy: 0.5911 - val_loss: 1.3824 - val_accuracy: 0.2933\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 0.8293 - accuracy: 0.6541 - val_loss: 1.3993 - val_accuracy: 0.2933\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 0.7337 - accuracy: 0.7067 - val_loss: 1.4278 - val_accuracy: 0.3067\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.7109 - accuracy: 0.7096 - val_loss: 1.4366 - val_accuracy: 0.2933\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.6403 - accuracy: 0.7526 - val_loss: 1.5471 - val_accuracy: 0.2800\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.5596 - accuracy: 0.7748 - val_loss: 1.6896 - val_accuracy: 0.2933\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.5598 - accuracy: 0.7770 - val_loss: 1.4416 - val_accuracy: 0.3067\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.4860 - accuracy: 0.8148 - val_loss: 1.7114 - val_accuracy: 0.2800\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.4345 - accuracy: 0.8311 - val_loss: 1.9371 - val_accuracy: 0.2933\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.3645 - accuracy: 0.8570 - val_loss: 1.8446 - val_accuracy: 0.3267\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.3786 - accuracy: 0.8556 - val_loss: 1.8174 - val_accuracy: 0.3200\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.3061 - accuracy: 0.8822 - val_loss: 1.8619 - val_accuracy: 0.2733\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.2716 - accuracy: 0.9052 - val_loss: 2.0225 - val_accuracy: 0.3333\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.2398 - accuracy: 0.9148 - val_loss: 1.5302 - val_accuracy: 0.3800\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.2073 - accuracy: 0.9356 - val_loss: 1.6676 - val_accuracy: 0.4200\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1789 - accuracy: 0.9415 - val_loss: 1.8568 - val_accuracy: 0.3867\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1708 - accuracy: 0.9400 - val_loss: 1.6767 - val_accuracy: 0.4733\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1689 - accuracy: 0.9422 - val_loss: 1.3278 - val_accuracy: 0.5267\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.1569 - accuracy: 0.9452 - val_loss: 1.4547 - val_accuracy: 0.6000\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1502 - accuracy: 0.9444 - val_loss: 1.2694 - val_accuracy: 0.6067\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1221 - accuracy: 0.9652 - val_loss: 1.2458 - val_accuracy: 0.6000\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1734 - accuracy: 0.9393 - val_loss: 1.0252 - val_accuracy: 0.6267\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1299 - accuracy: 0.9496 - val_loss: 1.0371 - val_accuracy: 0.6133\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1482 - accuracy: 0.9459 - val_loss: 1.0231 - val_accuracy: 0.6333\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.1720 - accuracy: 0.9407 - val_loss: 0.8632 - val_accuracy: 0.6800\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.1462 - accuracy: 0.9496 - val_loss: 0.8614 - val_accuracy: 0.6800\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.0896 - accuracy: 0.9733 - val_loss: 0.8382 - val_accuracy: 0.7400\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.0553 - accuracy: 0.9830 - val_loss: 0.8444 - val_accuracy: 0.7133\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.0531 - accuracy: 0.9852 - val_loss: 0.8411 - val_accuracy: 0.7133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a135c07d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#séparer 10% des données train pour la validation  \n",
    "x_train_A, x_valid, y_train_A, y_valid = train_test_split(x_trainA, y_trainA, test_size=0.1, random_state=42) \n",
    "model.fit(x_train_A, y_train_A, batch_size = 64, epochs = 30, verbose = 1, validation_data = (x_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tF8WbWsKRgpe",
    "outputId": "f3512ef0-dc51-4fd9-886c-62d378e8b0c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score of the model trained on imagenet and tested on imagenet :  0.9410340189933777\n",
      "Test accuracy of the model trained on imagenet and tested on imagenet :  0.7080000042915344\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_testA, y_testA, verbose = 0 )\n",
    "print(\"Test Score of the model trained on imagenet and tested on imagenet : \", score[0])\n",
    "print(\"Test accuracy of the model trained on imagenet and tested on imagenet : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQb6f8QNUGmu",
    "outputId": "5dad6c92-e363-46d7-8c96-6fdccf8e2165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score of the model trained on imagenet and tested on museum data :  1.5610946416854858\n",
      "Test accuracy of the model trained on imagenet and tested on museum data :  0.5820000171661377\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_testB, y_testB, verbose = 0 )\n",
    "print(\"Test Score of the model trained on imagenet and tested on museum data : \", score[0])\n",
    "print(\"Test accuracy of the model trained on imagenet and tested on museum data : \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZgXh4ZmOqkG"
   },
   "source": [
    "Commentaires :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDIVGF9dbnSO"
   },
   "source": [
    "<h4> Entrainement et évaluation du modèle sur les données B</h4>\n",
    "\n",
    "<i>Attention à ne pas réutiliser la variable <b>model</b>, déjà entrainée sur A, il faut créer une nouvelle instance <b>model2</b> à partir des fonctions <b>conv_model()</b> et <b>classif_model()</b> définient précédemment.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVnJo3ZUbtRD",
    "outputId": "961e2083-3364-4a76-e265-5e6e78841d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "model_3 (Functional)         (None, 4096)              1110784   \n",
      "_________________________________________________________________\n",
      "model_4 (Functional)         (None, 4)                 4722180   \n",
      "=================================================================\n",
      "Total params: 5,832,964\n",
      "Trainable params: 5,831,812\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ximg = Input(shape=(x_trainA.shape[1], x_trainA.shape[2], x_trainA.shape[3]))\n",
    "\n",
    "l = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(ximg)\n",
    "l = BatchNormalization(axis=-1)(l)\n",
    "l = Activation('relu')(l)\n",
    "l = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(l)\n",
    "l = BatchNormalization(axis=-1)(l)\n",
    "l = Activation('relu')(l)\n",
    "l = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(l)\n",
    "l = BatchNormalization(axis=-1)(l)\n",
    "l = Activation('relu')(l)\n",
    "l = AveragePooling2D((4,4))(l)\n",
    "l = Conv2D(256, kernel_size=(3,3), strides=(2,2), padding='same')(l)\n",
    "l = BatchNormalization(axis=-1)(l)\n",
    "l = Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same')(l)\n",
    "l = AveragePooling2D((2,2))(l)\n",
    "l = Activation('relu')(l)\n",
    "l = Dropout(0.2)(l)\n",
    "feat_layer = Flatten()(l)\n",
    "\n",
    "# conv_model(ximg) retourne la couche 'feat_layer' : 4096 dimensions pour une image 64x64x3\n",
    "conv_model = Model(ximg, feat_layer) \n",
    "\n",
    "# Couches de classification\n",
    "xfeat = Input(shape=(4096,))\n",
    "y = Dense(1024, activation='relu')(xfeat)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense(512, activation='relu')(y)\n",
    "out_layer = Dense(num_classes, activation='softmax')(y)\n",
    "\n",
    "# classif_model(xfeat) renvoie la couche sortie du classifieur : 4 dimensions\n",
    "classif_model = Model(xfeat, out_layer) \n",
    "\n",
    "# Modèle CNN : représentation + classifier\n",
    "feat = conv_model(ximg)\n",
    "clf = classif_model(feat)\n",
    "model2 = Model(ximg, clf)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EozG_gywYq-X",
    "outputId": "e69ab0b9-bd44-43dd-b69f-8eb76aa2c070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3450 - accuracy: 0.3400 - val_loss: 1.3775 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.0779 - accuracy: 0.4800 - val_loss: 1.3754 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9863 - accuracy: 0.6200 - val_loss: 1.3710 - val_accuracy: 0.6000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7825 - accuracy: 0.7400 - val_loss: 1.3671 - val_accuracy: 0.6000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6734 - accuracy: 0.8200 - val_loss: 1.3639 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6017 - accuracy: 0.8200 - val_loss: 1.3600 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5461 - accuracy: 0.8200 - val_loss: 1.3566 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4587 - accuracy: 0.9200 - val_loss: 1.3520 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3502 - accuracy: 0.9600 - val_loss: 1.3471 - val_accuracy: 0.6000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3160 - accuracy: 0.9200 - val_loss: 1.3424 - val_accuracy: 0.8000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2486 - accuracy: 0.9400 - val_loss: 1.3383 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2404 - accuracy: 0.9400 - val_loss: 1.3345 - val_accuracy: 0.6000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1907 - accuracy: 0.9600 - val_loss: 1.3313 - val_accuracy: 0.6000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 1.3288 - val_accuracy: 0.6000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1199 - accuracy: 1.0000 - val_loss: 1.3269 - val_accuracy: 0.4000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.4000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 1.3261 - val_accuracy: 0.4000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.3271 - val_accuracy: 0.4000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 1.3289 - val_accuracy: 0.4000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.4000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.4000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 1.3334 - val_accuracy: 0.4000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.3345 - val_accuracy: 0.4000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.3347 - val_accuracy: 0.4000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 1.3354 - val_accuracy: 0.4000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.3357 - val_accuracy: 0.4000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.3359 - val_accuracy: 0.4000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.3368 - val_accuracy: 0.4000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3382 - val_accuracy: 0.4000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.3398 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a134ca450>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#séparer 10% des données train pour la validation  \n",
    "\n",
    "x_train_B = x_trainB [0:50, :]\n",
    "y_train_B = y_trainB [0:50, :]\n",
    "x_train_data_B, x_valid_B, y_train_data_B, y_valid_B = train_test_split(x_train_B, y_train_B, test_size = 0.1, random_state = 42) \n",
    "model2.fit(x_train_B, y_train_B, batch_size = 64, epochs = 30, verbose = 1, validation_data = (x_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rd69e2Cce6XA",
    "outputId": "f75c78bf-179e-41ac-ff99-7385dc9e9bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score of the model trained and tested on museum data:  1.4217218160629272\n",
      "Test accuracy of the model trained and tested on museum data:  0.24199999868869781\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(x_testB, y_testB, verbose = 0 )\n",
    "print(\"Test Score of the model trained and tested on museum data: \", score[0])\n",
    "print(\"Test accuracy of the model trained and tested on museum data: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ82M78uxDXD"
   },
   "source": [
    "Commentaires :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "083Zv7bAb6eR"
   },
   "source": [
    "<h4>Finetuning sur B du modèle entrainé sur A</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXQU24qAcBcy",
    "outputId": "4e179d13-e6c8-42c4-a64d-c6e26cbee980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "model\n",
      "model_1\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers :\n",
    "  print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTeLA-au4Lrb",
    "outputId": "9716aa4f-3a82-4168-e8ba-eb9b5f0e1b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.3406 - accuracy: 0.6800 - val_loss: 1.5355 - val_accuracy: 0.8000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.1145 - accuracy: 0.7400 - val_loss: 1.2868 - val_accuracy: 0.8000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8435 - accuracy: 0.7800 - val_loss: 0.9909 - val_accuracy: 0.8000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4573 - accuracy: 0.8400 - val_loss: 0.5886 - val_accuracy: 0.8000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1690 - accuracy: 0.9400 - val_loss: 0.2401 - val_accuracy: 0.8000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1167 - accuracy: 0.9600 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0951 - accuracy: 0.9800 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1012 - accuracy: 0.9400 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1578 - accuracy: 0.9200 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0679 - accuracy: 0.9800 - val_loss: 0.0827 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0591 - accuracy: 0.9600 - val_loss: 0.1706 - val_accuracy: 0.8000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0318 - accuracy: 0.9800 - val_loss: 0.2072 - val_accuracy: 0.8000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.8000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.8000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.8000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.8000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.8000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.8000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.8000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.8000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.8000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.8000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.8000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.8000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.8000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0425 - accuracy: 0.9800 - val_loss: 0.1581 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a131fcc10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers :\n",
    "  if layer.name == 'input_3':\n",
    "       layer.trainable = False\n",
    "\n",
    "for layer in model.layers :\n",
    "  if layer.name == 'model_3':\n",
    "       layer.trainable = False \n",
    "\n",
    "model.fit(x_train_B, y_train_B, batch_size = 64, epochs = 30, verbose = 1, validation_data = (x_valid_B, y_valid_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bti5on_O7Rom",
    "outputId": "76d3eccf-a750-4fca-b265-fe22bc7cf03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with finetuning:  3.147972583770752\n",
      "Test accuracy finetuning:  0.4480000138282776\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_testB, y_testB, verbose = 0 )\n",
    "print(\"Test Score with finetuning: \", score[0])\n",
    "print(\"Test accuracy finetuning: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-3j2kTBxEat"
   },
   "source": [
    "Commentaires :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGTo8Gnyx-8s"
   },
   "source": [
    "<table>\n",
    "  <thead>\n",
    "    <th></th><th>Accuracy train A</th><th>Accuracy dev A</th><th>Accuracy test A</th><th>Accuracy train B</th><th>Accuracy dev B</th><th>Accuracy test B</th>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><th>Entrainement sur A</th><td>###</td><td>###</td><td>###</td><td>###</td><td>###</td><td>###</td></tr>\n",
    "    <tr><th>Entrainement sur B</th><td>###</td><td>###</td><td>###</td><td>###</td><td>###</td><td>###</td></tr>\n",
    "    <tr><th>Entrainement sur A <br/>+ Finetuning sur B</th><td>###</td><td>###</td><td>###</td><td>###</td><td>###</td><td>###</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Commentaires :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vv5WxG2cRgu"
   },
   "source": [
    "\n",
    "<h2>Partie 2 : Adaptation de domaine par alignement des activations</h2>\n",
    "\n",
    "Cette partie consiste à implémenter et évaluer un modèle inspiré de l'article <a href=\"https://arxiv.org/pdf/1607.01719.pdf\">Deep CORAL: Correlation Alignment for Deep Domain Adaptation [Sun & Saenko, 2016] </a>, dont la figure suivante illustre le fonctionnement. \n",
    "\n",
    "<center><img src=\"http://stephane.ayache.perso.luminy.univ-amu.fr/examdeep/coral16.png\" width=\"50%\" /></center>\n",
    "\n",
    "Considérez les instructions suivantes :\n",
    "- Utilisez les mêmes modules de convolutions que dans la Partie 1 afin de rester comparable. Pour cela, considérez une nouvelle instance <b>conv_model3</b> comme effectué précédemment.\n",
    "- Seules les couches de convolutions sont partagées. cf https://keras.io/getting-started/functional-api-guide/#shared-layers\n",
    "- Seulement deux couches denses après les convolutions (ie: fc6 et fc7), dropout entre les deux.\n",
    "- Version simplifiée de la <i>CORAL loss</i> : minimisation de la distance entre les dernières couches denses (et/ou maximisation de la corrélation). Utilisez l'une des couches documentées sur la page suivante : https://keras.io/layers/merge/ \n",
    "- Entrainez pendant 50 epochs, avec minibatchs = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhO-2mGcErz7"
   },
   "source": [
    "<h4> Définition du modèle </h4>\n",
    "\n",
    "xA et xB sont les données des deux domaines, yA est la sortie du classifieur pour les données de xA dans le domaine source, et <i>coral</i> correspond à la métrique (distance ou corrélation) entre un minibatch d'exemples xA et xB, dans les deux domaines. Le modèle optimise les deux loss : <i>categorical_crossentropy</i> pour classer les images du domaine source ; et <i>mse</i> qui minimise (ou maximise) la métrique considérée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCf5TACncWUd",
    "outputId": "c354fac5-2f92-43a9-f917-0ae5dab00603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_10 (Functional)           (None, 4096)         1110784     input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_11 (Functional)           (None, 4096)         33562624    model_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_12 (Functional)           (None, 4096)         33562624    model_10[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 4096)         0           model_11[0][0]                   \n",
      "                                                                 model_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_13 (Functional)           (None, 4)            4722180     model_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           subtract[0][0]                   \n",
      "                                                                 subtract[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 72,958,212\n",
      "Trainable params: 72,957,060\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "xA = Input(shape=(x_trainA.shape[1], x_trainA.shape[2], x_trainA.shape[3]))\n",
    "xB = Input(shape=(x_trainA.shape[1], x_trainA.shape[2], x_trainA.shape[3]))\n",
    "\n",
    "\n",
    "conv_model_3 = Model(ximg, feat_layer)\n",
    "\n",
    "conv_model_A = conv_model_3(xA)\n",
    "conv_model_B = conv_model_3(xB)\n",
    "\n",
    "xfeat = Input(shape = (4096,))\n",
    "y = Dense (4096, activation='relu')(xfeat)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense (4096, activation='relu')(y)\n",
    "fc_model_A = Model(xfeat, y)\n",
    "\n",
    "\n",
    "xfeat = Input(shape = (4096,))\n",
    "y = Dense (4096, activation='relu')(xfeat)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense (4096, activation='relu')(y)\n",
    "fc_model_B = Model(xfeat, y)\n",
    "\n",
    "model_A = fc_model_A(conv_model_A)\n",
    "model_B = fc_model_B(conv_model_B)\n",
    "\n",
    "#couches de classification\n",
    "xfeat = Input(shape = (4096,))\n",
    "y = Dense (1024, activation='relu')(xfeat)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense (512, activation='relu')(y)\n",
    "out_layer = Dense (num_classes, activation='softmax')(y)\n",
    "\n",
    "#classif_model\n",
    "model_classification = Model(xfeat, out_layer)\n",
    "yA = model_classification(model_A)\n",
    "\n",
    "coral = tf.keras.layers.Subtract()([model_A, model_B])\n",
    "coral = tf.keras.layers.Dot(axes=1)([coral, coral])\n",
    "\n",
    "\n",
    "model4 = Model([xA,xB],[yA, coral])\n",
    "model4.compile(loss=['categorical_crossentropy','mse'], optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "print(model4.summary())\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKBerCO6mKyQ"
   },
   "source": [
    "<h4> Entrainement du modèle d'adaptation par alignement </h4>\n",
    "\n",
    "Selon le critère <i>coral</i> que vous optimisez, considérez le vecteur objectif ne contenant que des 1 ou que des 0.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0R1UYCtvmRK7",
    "outputId": "d2e32bbd-b0e6-4912-8461-23bf716081fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 16s 1s/step - loss: 240954.9688 - model_13_loss: 1.4103 - dot_loss: 240953.5781 - model_13_accuracy: 0.2711 - dot_accuracy: 0.0000e+00 - val_loss: 1.5058 - val_model_13_loss: 1.3871 - val_dot_loss: 0.1187 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 1286.3191 - model_13_loss: 1.3832 - dot_loss: 1284.9358 - model_13_accuracy: 0.2644 - dot_accuracy: 0.0000e+00 - val_loss: 1.4992 - val_model_13_loss: 1.3864 - val_dot_loss: 0.1128 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 516.1292 - model_13_loss: 1.3832 - dot_loss: 514.7461 - model_13_accuracy: 0.2756 - dot_accuracy: 0.0000e+00 - val_loss: 1.5528 - val_model_13_loss: 1.3864 - val_dot_loss: 0.1664 - val_model_13_accuracy: 0.2867 - val_dot_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 337.6245 - model_13_loss: 1.3797 - dot_loss: 336.2447 - model_13_accuracy: 0.2904 - dot_accuracy: 0.0000e+00 - val_loss: 1.6335 - val_model_13_loss: 1.3860 - val_dot_loss: 0.2475 - val_model_13_accuracy: 0.2733 - val_dot_accuracy: 0.4867\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 258.5497 - model_13_loss: 1.3735 - dot_loss: 257.1762 - model_13_accuracy: 0.3437 - dot_accuracy: 0.0000e+00 - val_loss: 1.7350 - val_model_13_loss: 1.3861 - val_dot_loss: 0.3489 - val_model_13_accuracy: 0.2733 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 8s 720ms/step - loss: 220.7795 - model_13_loss: 1.3711 - dot_loss: 219.4084 - model_13_accuracy: 0.3511 - dot_accuracy: 0.0000e+00 - val_loss: 1.8526 - val_model_13_loss: 1.3862 - val_dot_loss: 0.4664 - val_model_13_accuracy: 0.2867 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 196.6705 - model_13_loss: 1.3683 - dot_loss: 195.3022 - model_13_accuracy: 0.3652 - dot_accuracy: 0.0000e+00 - val_loss: 1.9830 - val_model_13_loss: 1.3860 - val_dot_loss: 0.5970 - val_model_13_accuracy: 0.2733 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 177.1563 - model_13_loss: 1.3652 - dot_loss: 175.7911 - model_13_accuracy: 0.3674 - dot_accuracy: 0.0000e+00 - val_loss: 2.1212 - val_model_13_loss: 1.3864 - val_dot_loss: 0.7347 - val_model_13_accuracy: 0.2400 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 161.6345 - model_13_loss: 1.3592 - dot_loss: 160.2754 - model_13_accuracy: 0.3889 - dot_accuracy: 0.0000e+00 - val_loss: 2.2664 - val_model_13_loss: 1.3851 - val_dot_loss: 0.8813 - val_model_13_accuracy: 0.3333 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 148.9395 - model_13_loss: 1.3549 - dot_loss: 147.5846 - model_13_accuracy: 0.3956 - dot_accuracy: 0.0000e+00 - val_loss: 2.4047 - val_model_13_loss: 1.3844 - val_dot_loss: 1.0204 - val_model_13_accuracy: 0.3133 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 8s 716ms/step - loss: 138.6196 - model_13_loss: 1.3498 - dot_loss: 137.2698 - model_13_accuracy: 0.4126 - dot_accuracy: 0.0000e+00 - val_loss: 2.5167 - val_model_13_loss: 1.3827 - val_dot_loss: 1.1341 - val_model_13_accuracy: 0.3200 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 128.9246 - model_13_loss: 1.3443 - dot_loss: 127.5803 - model_13_accuracy: 0.4304 - dot_accuracy: 0.0000e+00 - val_loss: 2.5601 - val_model_13_loss: 1.3816 - val_dot_loss: 1.1785 - val_model_13_accuracy: 0.3067 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 118.6511 - model_13_loss: 1.3373 - dot_loss: 117.3139 - model_13_accuracy: 0.4430 - dot_accuracy: 0.0000e+00 - val_loss: 2.5664 - val_model_13_loss: 1.3807 - val_dot_loss: 1.1857 - val_model_13_accuracy: 0.2467 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 108.6267 - model_13_loss: 1.3257 - dot_loss: 107.3010 - model_13_accuracy: 0.4526 - dot_accuracy: 0.0000e+00 - val_loss: 2.5182 - val_model_13_loss: 1.3782 - val_dot_loss: 1.1400 - val_model_13_accuracy: 0.3200 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 97.8194 - model_13_loss: 1.3214 - dot_loss: 96.4980 - model_13_accuracy: 0.4474 - dot_accuracy: 0.0000e+00 - val_loss: 2.4230 - val_model_13_loss: 1.3770 - val_dot_loss: 1.0460 - val_model_13_accuracy: 0.2800 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 90.5523 - model_13_loss: 1.3191 - dot_loss: 89.2332 - model_13_accuracy: 0.4444 - dot_accuracy: 0.0000e+00 - val_loss: 2.3119 - val_model_13_loss: 1.3761 - val_dot_loss: 0.9359 - val_model_13_accuracy: 0.2667 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 80.4769 - model_13_loss: 1.3066 - dot_loss: 79.1703 - model_13_accuracy: 0.4681 - dot_accuracy: 0.0000e+00 - val_loss: 2.1933 - val_model_13_loss: 1.3739 - val_dot_loss: 0.8194 - val_model_13_accuracy: 0.3000 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 75.4698 - model_13_loss: 1.3070 - dot_loss: 74.1628 - model_13_accuracy: 0.4526 - dot_accuracy: 0.0000e+00 - val_loss: 2.0918 - val_model_13_loss: 1.3728 - val_dot_loss: 0.7189 - val_model_13_accuracy: 0.2800 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 67.6506 - model_13_loss: 1.3021 - dot_loss: 66.3485 - model_13_accuracy: 0.4504 - dot_accuracy: 0.0000e+00 - val_loss: 2.0045 - val_model_13_loss: 1.3723 - val_dot_loss: 0.6323 - val_model_13_accuracy: 0.2667 - val_dot_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 63.5689 - model_13_loss: 1.2971 - dot_loss: 62.2718 - model_13_accuracy: 0.4526 - dot_accuracy: 0.0000e+00 - val_loss: 1.9369 - val_model_13_loss: 1.3736 - val_dot_loss: 0.5633 - val_model_13_accuracy: 0.2400 - val_dot_accuracy: 0.0333\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 57.9878 - model_13_loss: 1.2930 - dot_loss: 56.6948 - model_13_accuracy: 0.4504 - dot_accuracy: 0.0000e+00 - val_loss: 1.8851 - val_model_13_loss: 1.3745 - val_dot_loss: 0.5106 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.1067\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 54.8161 - model_13_loss: 1.2983 - dot_loss: 53.5178 - model_13_accuracy: 0.4526 - dot_accuracy: 0.0000e+00 - val_loss: 1.8526 - val_model_13_loss: 1.3768 - val_dot_loss: 0.4757 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.1733\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 51.5810 - model_13_loss: 1.2893 - dot_loss: 50.2917 - model_13_accuracy: 0.4548 - dot_accuracy: 0.0000e+00 - val_loss: 1.8274 - val_model_13_loss: 1.3804 - val_dot_loss: 0.4470 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.2333\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 47.4680 - model_13_loss: 1.2922 - dot_loss: 46.1758 - model_13_accuracy: 0.4370 - dot_accuracy: 0.0000e+00 - val_loss: 1.8047 - val_model_13_loss: 1.3815 - val_dot_loss: 0.4233 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.3000\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 45.3804 - model_13_loss: 1.2902 - dot_loss: 44.0902 - model_13_accuracy: 0.4207 - dot_accuracy: 0.0000e+00 - val_loss: 1.7865 - val_model_13_loss: 1.3836 - val_dot_loss: 0.4029 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.3533\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 8s 720ms/step - loss: 42.9547 - model_13_loss: 1.2959 - dot_loss: 41.6588 - model_13_accuracy: 0.3985 - dot_accuracy: 0.0000e+00 - val_loss: 1.7584 - val_model_13_loss: 1.3837 - val_dot_loss: 0.3747 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.4400\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 8s 721ms/step - loss: 40.2310 - model_13_loss: 1.2938 - dot_loss: 38.9372 - model_13_accuracy: 0.4104 - dot_accuracy: 0.0000e+00 - val_loss: 1.7286 - val_model_13_loss: 1.3830 - val_dot_loss: 0.3456 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.4733\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 38.6103 - model_13_loss: 1.2954 - dot_loss: 37.3150 - model_13_accuracy: 0.4067 - dot_accuracy: 0.0000e+00 - val_loss: 1.6954 - val_model_13_loss: 1.3819 - val_dot_loss: 0.3135 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.5467\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 35.7321 - model_13_loss: 1.2967 - dot_loss: 34.4354 - model_13_accuracy: 0.4230 - dot_accuracy: 0.0000e+00 - val_loss: 1.6566 - val_model_13_loss: 1.3836 - val_dot_loss: 0.2730 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.6533\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 31.8483 - model_13_loss: 1.2990 - dot_loss: 30.5493 - model_13_accuracy: 0.4126 - dot_accuracy: 0.0000e+00 - val_loss: 1.6124 - val_model_13_loss: 1.3833 - val_dot_loss: 0.2291 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.7267\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 29.8456 - model_13_loss: 1.2916 - dot_loss: 28.5540 - model_13_accuracy: 0.4015 - dot_accuracy: 0.0000e+00 - val_loss: 1.5679 - val_model_13_loss: 1.3832 - val_dot_loss: 0.1847 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.7933\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 8s 721ms/step - loss: 26.8359 - model_13_loss: 1.2955 - dot_loss: 25.5404 - model_13_accuracy: 0.4200 - dot_accuracy: 0.0000e+00 - val_loss: 1.5257 - val_model_13_loss: 1.3829 - val_dot_loss: 0.1427 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.8667\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 25.4692 - model_13_loss: 1.2876 - dot_loss: 24.1816 - model_13_accuracy: 0.4126 - dot_accuracy: 0.0000e+00 - val_loss: 1.4884 - val_model_13_loss: 1.3833 - val_dot_loss: 0.1050 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.9200\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 8s 720ms/step - loss: 23.1196 - model_13_loss: 1.2975 - dot_loss: 21.8221 - model_13_accuracy: 0.3881 - dot_accuracy: 0.0000e+00 - val_loss: 1.4596 - val_model_13_loss: 1.3850 - val_dot_loss: 0.0746 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.9533\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 21.1393 - model_13_loss: 1.2949 - dot_loss: 19.8443 - model_13_accuracy: 0.3874 - dot_accuracy: 0.0000e+00 - val_loss: 1.4365 - val_model_13_loss: 1.3847 - val_dot_loss: 0.0518 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.9800\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 20.4462 - model_13_loss: 1.2836 - dot_loss: 19.1626 - model_13_accuracy: 0.4119 - dot_accuracy: 0.0015 - val_loss: 1.4204 - val_model_13_loss: 1.3848 - val_dot_loss: 0.0355 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 0.9800\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 18.5013 - model_13_loss: 1.2850 - dot_loss: 17.2163 - model_13_accuracy: 0.4170 - dot_accuracy: 0.0037 - val_loss: 1.4071 - val_model_13_loss: 1.3834 - val_dot_loss: 0.0237 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 17.4882 - model_13_loss: 1.2940 - dot_loss: 16.1941 - model_13_accuracy: 0.3933 - dot_accuracy: 0.0074 - val_loss: 1.3987 - val_model_13_loss: 1.3830 - val_dot_loss: 0.0156 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 17.0881 - model_13_loss: 1.2991 - dot_loss: 15.7891 - model_13_accuracy: 0.3785 - dot_accuracy: 0.0170 - val_loss: 1.3932 - val_model_13_loss: 1.3828 - val_dot_loss: 0.0104 - val_model_13_accuracy: 0.2400 - val_dot_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 15.7913 - model_13_loss: 1.3025 - dot_loss: 14.4888 - model_13_accuracy: 0.3844 - dot_accuracy: 0.0333 - val_loss: 1.3894 - val_model_13_loss: 1.3824 - val_dot_loss: 0.0069 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 14.9778 - model_13_loss: 1.2891 - dot_loss: 13.6886 - model_13_accuracy: 0.3993 - dot_accuracy: 0.0578 - val_loss: 1.3877 - val_model_13_loss: 1.3831 - val_dot_loss: 0.0046 - val_model_13_accuracy: 0.2400 - val_dot_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 14.3711 - model_13_loss: 1.2980 - dot_loss: 13.0732 - model_13_accuracy: 0.3933 - dot_accuracy: 0.0704 - val_loss: 1.3856 - val_model_13_loss: 1.3825 - val_dot_loss: 0.0031 - val_model_13_accuracy: 0.2867 - val_dot_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 13.1561 - model_13_loss: 1.2873 - dot_loss: 11.8689 - model_13_accuracy: 0.3852 - dot_accuracy: 0.0956 - val_loss: 1.3853 - val_model_13_loss: 1.3831 - val_dot_loss: 0.0021 - val_model_13_accuracy: 0.2467 - val_dot_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 8s 716ms/step - loss: 13.0981 - model_13_loss: 1.2867 - dot_loss: 11.8113 - model_13_accuracy: 0.3933 - dot_accuracy: 0.1170 - val_loss: 1.3849 - val_model_13_loss: 1.3834 - val_dot_loss: 0.0014 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 11.9737 - model_13_loss: 1.2927 - dot_loss: 10.6810 - model_13_accuracy: 0.4007 - dot_accuracy: 0.1207 - val_loss: 1.3846 - val_model_13_loss: 1.3836 - val_dot_loss: 9.9552e-04 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 12.3307 - model_13_loss: 1.2977 - dot_loss: 11.0330 - model_13_accuracy: 0.3748 - dot_accuracy: 0.1541 - val_loss: 1.3851 - val_model_13_loss: 1.3844 - val_dot_loss: 6.8723e-04 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 8s 717ms/step - loss: 11.5827 - model_13_loss: 1.2951 - dot_loss: 10.2876 - model_13_accuracy: 0.4007 - dot_accuracy: 0.1541 - val_loss: 1.3849 - val_model_13_loss: 1.3845 - val_dot_loss: 4.7850e-04 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 8s 716ms/step - loss: 11.7714 - model_13_loss: 1.2856 - dot_loss: 10.4858 - model_13_accuracy: 0.4015 - dot_accuracy: 0.2030 - val_loss: 1.3862 - val_model_13_loss: 1.3858 - val_dot_loss: 3.3477e-04 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 11.1933 - model_13_loss: 1.2881 - dot_loss: 9.9052 - model_13_accuracy: 0.3852 - dot_accuracy: 0.2007 - val_loss: 1.3853 - val_model_13_loss: 1.3851 - val_dot_loss: 2.3659e-04 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 8s 718ms/step - loss: 10.8964 - model_13_loss: 1.3062 - dot_loss: 9.5902 - model_13_accuracy: 0.3919 - dot_accuracy: 0.2326 - val_loss: 1.3841 - val_model_13_loss: 1.3839 - val_dot_loss: 1.6877e-04 - val_model_13_accuracy: 0.2267 - val_dot_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a131aa190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = np.ones((len(x_trainA),1)) # ou zeros = np.zeros((len(x_trainA),1))\n",
    "\n",
    "# A compléter\n",
    "zeros = np.zeros((len(x_trainA),1))\n",
    "model4.fit([x_trainA, x_trainB], [y_trainA, zeros], batch_size = batch_size, epochs = n_epochs, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP_v8XaKcZJd"
   },
   "source": [
    "<h4>Evaluation sur les datasets A et B</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTo7eJ6icecX",
    "outputId": "5136742f-3302-4e5a-a51f-a0a5c9588ded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 211ms/step - loss: 1.3863 - model_13_loss: 1.3862 - dot_loss: 1.0476e-04 - model_13_accuracy: 0.2540 - dot_accuracy: 1.0000\n",
      "Test Score:  3.147972583770752\n",
      "Test accuracy:  0.4480000138282776\n"
     ]
    }
   ],
   "source": [
    "score_alignement = model4.evaluate([x_testB, x_testB],[y_testB, zeros[:500]], batch_size = batch_size)\n",
    "print(\"Test Score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP_transfer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
