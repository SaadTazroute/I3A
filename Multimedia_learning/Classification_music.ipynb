{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3802c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e14a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/phillyflingo/Desktop/ECM/M2 IAAA/temps2/SAM/projet\n"
     ]
    }
   ],
   "source": [
    "%cd projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defd5568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, ActivityRegularization, Lambda, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.layers import AveragePooling2D, Input\n",
    "from keras import backend as K \n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c19081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_msdi_path = 'msdi'  # Change this to configure your path to MSDI dataset\n",
    "\n",
    "\n",
    "def get_msdi_dataframe(msdi_path=_msdi_path):\n",
    "    return pd.read_csv(Path(msdi_path) / 'msdi_mapping.csv')\n",
    "\n",
    "\n",
    "def load_mfcc(entry, msdi_path=_msdi_path):\n",
    "    x = np.load(Path(msdi_path) / entry['mfcc'])\n",
    "    return x[entry['msd_track_id']]\n",
    "\n",
    "\n",
    "def load_img(entry, msdi_path=_msdi_path):\n",
    "    return plt.imread(Path(msdi_path) / entry['img'])\n",
    "\n",
    "\n",
    "def load_deep_audio_features(entry, msdi_path=_msdi_path):\n",
    "    subset_file = 'X_{}_audio_MSD-I.npy'.format(entry['set'])\n",
    "    x = np.load(Path(msdi_path) / 'deep_features' / subset_file)\n",
    "    idx = entry['deep_features']\n",
    "    return x[idx, :]\n",
    "\n",
    "\n",
    "def get_set(entry):\n",
    "    return entry['set']\n",
    "\n",
    "\n",
    "def get_label(entry):\n",
    "    return entry['genre']\n",
    "\n",
    "\n",
    "def get_label_list(msdi_path=_msdi_path):\n",
    "    df = pd.read_csv(Path(msdi_path) / 'labels.csv', header=None)\n",
    "    return list(df.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef157b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with 30712 entries\n",
      "################################################################################\n",
      "Labels: ['Blues', 'Country', 'Electronic', 'Folk', 'Jazz', 'Latin', 'Metal', 'New Age', 'Pop', 'Punk', 'Rap', 'Reggae', 'RnB', 'Rock', 'World']\n",
      "################################################################################\n",
      "Entry 100:\n",
      "################################################################################\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Exemple d'utilisation\n",
    "    msdi = get_msdi_dataframe(_msdi_path)\n",
    "    print('Dataset with {} entries'.format(len(msdi)))\n",
    "    print('#' * 80)\n",
    "    print('Labels:', get_label_list())\n",
    "    print('#' * 80)\n",
    "\n",
    "    entry_idx = 100\n",
    "    one_entry = msdi.loc[entry_idx]\n",
    "    print('Entry {}:'.format(entry_idx))\n",
    "    print('#' * 80)\n",
    "    img = load_deep_audio_features(one_entry, _msdi_path)\n",
    "    print(img[1300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63fdf49",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4335807fa3cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0m_msdi_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'msdi'\u001b[0m  \u001b[0;31m# Change this to configure your path to MSDI dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_msdi_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-4335807fa3cf>\u001b[0m in \u001b[0;36mget_X_y\u001b[0;34m(msdi_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcpt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m  \u001b[0mget_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_deep_audio_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsdi_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6e4fc8ad482f>\u001b[0m in \u001b[0;36mload_deep_audio_features\u001b[0;34m(entry, msdi_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_deep_audio_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsdi_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_msdi_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msubset_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'X_{}_audio_MSD-I.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'set'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsdi_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'deep_features'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msubset_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deep_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    440\u001b[0m                                          pickle_kwargs=pickle_kwargs)\n\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "def get_X_y(msdi_path):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    mfccs_lenghts = []\n",
    "    cpt = 0\n",
    "    msdi = get_msdi_dataframe(msdi_path)\n",
    "    for idx in range(len(msdi)):\n",
    "        entry = msdi.loc[idx]\n",
    "        cpt+=1\n",
    "        if  get_set(entry) =='train' :\n",
    "            x = load_deep_audio_features(entry, msdi_path)\n",
    "            X_train.append(x)\n",
    "            x=None\n",
    "            y = get_label(entry)\n",
    "            y_train.append(y)\n",
    "            if cpt/10 == 0:\n",
    "                print(cpt)\n",
    "        if  get_set(entry) =='test' :\n",
    "            print(cpt)\n",
    "            x = load_deep_audio_features(entry, msdi_path)\n",
    "            X_test.append(x)\n",
    "            x=None\n",
    "            y = get_label(entry)\n",
    "            y_test.append(y)\n",
    "        gc.collect()\n",
    "    print('end')\n",
    "    X_train = np.array(X_train,dtype=object)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test,dtype=object)\n",
    "    y_test = np.array(y_test)\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "_msdi_path = 'msdi'  # Change this to configure your path to MSDI dataset\n",
    "            \n",
    "X_train,y_train,X_test,y_test = get_X_y(_msdi_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34a252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03b762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b25a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_deep.npy',X_train)\n",
    "np.save('y_train_deep.npy',y_train)\n",
    "np.save('X_test_deep.npy',X_test)\n",
    "np.save('y_test_deep.npy',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3277512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7594fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "X_test = np.asarray(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train, y_test = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "#y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "labelencoder.fit(y_train)\n",
    "#labelencoder.fit(y_test)\n",
    "\n",
    "\n",
    "y_train = labelencoder.transform(y_train)\n",
    "#y_test = labelencoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b81957",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcee049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "input_shape\n",
    "# Layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 1, activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, 1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77114a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(features, labels, batch_size):\n",
    "    while True:\n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index = np.random.choice(len(features),1)\n",
    "            batch_features.extend(features[index])\n",
    "            batch_labels.extend(labels[index])\n",
    "        batch_features = np.array(batch_features)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        yield batch_features, batch_labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf518e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    \"\"\"\n",
    "    plots the confusion matrix\n",
    "    \"\"\"\n",
    "    matrix = confusion_matrix(y_true, y_pred)    \n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    plt.imshow(matrix)\n",
    "    ax.set_xticks(range(len(labels)));\n",
    "    ax.set_xticklabels(labels, rotation=0)\n",
    "    ax.set_yticks(range(len(labels)));\n",
    "    ax.set_yticklabels(labels)\n",
    "    max_confusions = 0\n",
    "    confused_classes = (-1, -1)\n",
    "    for i, true_label in enumerate(matrix):\n",
    "        for j, predicted_label in enumerate(true_label):\n",
    "            text = ax.text(j, i, matrix[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"w\");\n",
    "    plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "    plt.title(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(array, bins=1000, title=\"Histogram\", xlabel=\"x\", ylabel=\"y\"):\n",
    "    array  = np.array(array)\n",
    "    values, counts = np.unique(array, return_counts=True)\n",
    "\n",
    "    \n",
    "    plt.hist(array)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "plot_histogram(mfccs_lenghts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ae778",
   "metadata": {},
   "source": [
    "## Genre Classification : MFCC Features with CNN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0761612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x = Input(shape=input_shape, name='input')\n",
    "y0 = AveragePooling2D((14,14), padding='same')(x)# MaxPooling2D   AveragePooling2D ##### You may also use GlobalAveragePooling layers\n",
    "\n",
    "y0 = Lambda(lambda x: K.l2_normalize(x, axis=-1))(x)\n",
    "y0 = Flatten()(y0)\n",
    "\n",
    "y1 = Dense(n_classes, activation='softmax')(y0)\n",
    "\n",
    "model1 = Model(inputs=x,outputs=y1)\n",
    "\n",
    "#Combine the networks\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52569f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7024f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"X_train = np.asarray(X_train).astype(np.float32)\n",
    "#y_train = np.asarray(y_train).astype(np.float32)\n",
    "X_test = np.asarray(X_train).astype(np.float32)\n",
    "#y_test = np.asarray(y_train).astype(np.float32)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a928e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# reshape data to fit model\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "# one hot encode target values\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb0bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdc302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37bcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168c417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ab8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
